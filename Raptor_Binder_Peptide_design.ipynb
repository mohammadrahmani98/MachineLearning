{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mohammadrahmani98/MachineLearning/blob/main/Raptor_Binder_Peptide_design.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Phase 1 Literature review**\n",
        "\n",
        "This section of the Raptor notebook provides an automated tool to suggest relevant scientific publications for a specified target protein. By leveraging PubMed's extensive database, the tool identifies experimental studies that have discovered binding pockets, aiding in the design of binder peptides.\n",
        "\n",
        "* You need to modify the last line of code of this part to write your protein target name to get your references,\n",
        "* The suggested refrences can easily help to access the last relevant published paper which worked on the same targe.\n",
        "\n"
      ],
      "metadata": {
        "id": "Hxv7eBITg-MC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install requests beautifulsoup4 spacy matplotlib seaborn xmltodict\n",
        "!python -m spacy download en_core_web_sm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oaUFrZcNlAYb",
        "outputId": "5e72350b-9de8-4d43-850d-ccc2642de8e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.31.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (4.12.3)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.7.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (0.13.1)\n",
            "Collecting xmltodict\n",
            "  Using cached xmltodict-0.13.0-py2.py3-none-any.whl (10.0 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.7.4)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4) (2.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.12.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (4.66.4)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.8.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (24.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.4.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.25.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.10/dist-packages (from seaborn) (2.0.3)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2->seaborn) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2->seaborn) (2024.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.20.1)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.7.1)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.18.1)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (2.1.5)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.16.1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.14.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
            "Installing collected packages: xmltodict\n",
            "Successfully installed xmltodict-0.13.0\n",
            "Collecting en-core-web-sm==3.7.1\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m35.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /usr/local/lib/python3.10/dist-packages (from en-core-web-sm==3.7.1) (3.7.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.12.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.66.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.8.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (24.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.4.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.25.2)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.20.1)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2024.7.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (13.7.1)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.18.1)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (7.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.1.5)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.16.1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.14.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.2)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Import necessary libraries\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import spacy\n",
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from collections import defaultdict\n",
        "import xmltodict\n",
        "\n",
        "# NLP Processing\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Function to search PubMed using the API\n",
        "def search_pubmed(protein_name, max_results=20):\n",
        "    api_key = \"4266b303fbe3a527d5d3f3d64b3ac2dac509\"  # Replace with your PubMed API key\n",
        "    search_url = f\"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi?db=pubmed&term={protein_name}+binding+pocket+AND+experimental&retmax={max_results}&retmode=json&api_key={api_key}\"\n",
        "    response = requests.get(search_url)\n",
        "    data = response.json()\n",
        "    return data['esearchresult']['idlist']\n",
        "\n",
        "# Function to fetch details of articles from PubMed using the API\n",
        "def fetch_article_details(pubmed_ids):\n",
        "    api_key = \"4266b303fbe3a527d5d3f3d64b3ac2dac509\"  # Replace with your PubMed API key\n",
        "    ids = \",\".join(pubmed_ids)\n",
        "    fetch_url = f\"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=pubmed&id={ids}&retmode=xml&api_key={api_key}\"\n",
        "    response = requests.get(fetch_url)\n",
        "    articles = xmltodict.parse(response.content)\n",
        "    return articles['PubmedArticleSet']['PubmedArticle']\n",
        "\n",
        "# Extract and Clean Text\n",
        "def clean_text(text):\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    return text.strip()\n",
        "\n",
        "# Extract relevant information using NLP\n",
        "def extract_protein_info(text):\n",
        "    doc = nlp(text)\n",
        "    proteins = defaultdict(list)\n",
        "    for ent in doc.ents:\n",
        "        if ent.label_ == \"PROTEIN\":\n",
        "            proteins[ent.text].append(ent.sent.text)\n",
        "    return proteins\n",
        "\n",
        "# Filter for experimental studies mentioning binding pockets\n",
        "def filter_relevant_articles(articles):\n",
        "    relevant_articles = []\n",
        "    for article in articles:\n",
        "        try:\n",
        "            abstract = article['MedlineCitation']['Article']['Abstract']['AbstractText']\n",
        "            if 'binding pocket' in abstract and 'experimental' in abstract:\n",
        "                relevant_articles.append(article)\n",
        "        except:\n",
        "            continue\n",
        "    return relevant_articles[:8]  # Limit to top 8 relevant articles\n",
        "\n",
        "# Main Function\n",
        "def main(protein_name):\n",
        "    # Step 1: Search PubMed for relevant articles\n",
        "    pubmed_ids = search_pubmed(protein_name)\n",
        "\n",
        "    # Step 2: Fetch details of the articles\n",
        "    articles = fetch_article_details(pubmed_ids)\n",
        "\n",
        "    # Step 3: Filter and select the most relevant articles\n",
        "    relevant_articles = filter_relevant_articles(articles)\n",
        "\n",
        "    # Step 4: Print references\n",
        "    print(\"Suggested References:\")\n",
        "    for article in relevant_articles:\n",
        "        title = article['MedlineCitation']['Article']['ArticleTitle']\n",
        "        journal = article['MedlineCitation']['Article']['Journal']['Title']\n",
        "        pub_date = article['MedlineCitation']['Article']['Journal']['JournalIssue']['PubDate']\n",
        "        pub_year = pub_date.get('Year', 'Unknown Year')\n",
        "        authors = article['MedlineCitation']['Article']['AuthorList']['Author']\n",
        "        author_names = \", \".join([f\"{author.get('LastName', '')} {author.get('Initials', '')}\" for author in authors if 'LastName' in author and 'Initials' in author])\n",
        "        print(f\"Title: {title}\\nJournal: {journal}\\nPublication Year: {pub_year}\\nAuthors: {author_names}\\n\")\n",
        "\n",
        "# Example usage:\n",
        "main(\"trypsin\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1prbtGH6hHST",
        "outputId": "a271cd5e-b630-4966-a364-69d618123f2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Suggested References:\n",
            "Title: New insights on the binding of butyl-paraben to trypsin: experimental and computational approaches.\n",
            "Journal: Journal of biomolecular structure & dynamics\n",
            "Publication Year: 2023\n",
            "Authors: Mostafavi ES, Asoodeh A, Chamani J\n",
            "\n",
            "Title: Water Network in the Binding Pocket of Fluorinated BPTI-Trypsin Complexes─Insights from Simulation and Experiment.\n",
            "Journal: The journal of physical chemistry. B\n",
            "Publication Year: 2022\n",
            "Authors: Wehrhan L, Leppkes J, Dimos N, Loll B, Koksch B, Keller BG\n",
            "\n",
            "Title: Structural insights on the effects of mutation of a charged binding pocket residue on phosphopeptide binding to 14-3-3ζ protein.\n",
            "Journal: Proteins\n",
            "Publication Year: 2022\n",
            "Authors: T S S, Dalvi S, Venkatraman P, Vemparala S\n",
            "\n",
            "Title: Interactive molecular dynamics in virtual reality for accurate flexible protein-ligand docking.\n",
            "Journal: PloS one\n",
            "Publication Year: 2020\n",
            "Authors: Deeks HM, Walters RK, Hare SR, O'Connor MB, Mulholland AJ, Glowacki DR\n",
            "\n",
            "Title: Exploring the Ligand Binding/Unbinding Pathway by Selectively Enhanced Sampling of Ligand in a Protein-Ligand Complex.\n",
            "Journal: The journal of physical chemistry. B\n",
            "Publication Year: 2019\n",
            "Authors: Shao Q, Zhu W\n",
            "\n",
            "Title: Solvent effects on ligand binding to a serine protease.\n",
            "Journal: Physical chemistry chemical physics : PCCP\n",
            "Publication Year: 2017\n",
            "Authors: Gopal SM, Klumpers F, Herrmann C, Schäfer LV\n",
            "\n",
            "Title: Kinetics of protein-ligand unbinding: Predicting pathways, rates, and rate-limiting steps.\n",
            "Journal: Proceedings of the National Academy of Sciences of the United States of America\n",
            "Publication Year: 2015\n",
            "Authors: Tiwary P, Limongelli V, Salvalaglio M, Parrinello M\n",
            "\n",
            "Title: Mechanism of gold nanoparticles-induced trypsin inhibition: a multi-technique approach.\n",
            "Journal: Molecular biology reports\n",
            "Publication Year: 2014\n",
            "Authors: Zhang H, Cao J, Wu S, Wang Y\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Phase 2 -3 .RFdiffusion + ProtienMPNN**\n",
        "RFdiffusion is a method for structure generation, with or without conditional information (a motif, target etc). It can perform a whole range of protein design challenges as we have outlined in the RFdiffusion\n",
        "\n",
        "[![DOI](https://img.shields.io/badge/DOI-10.1101/zenodo.8246977-blue)](https://www.biorxiv.org/content/10.1101/2022.12.09.519842v2)\n"
      ],
      "metadata": {
        "id": "IYFYtNGgkbh6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Instructions**\n",
        "---\n",
        "---\n",
        "\n",
        "Use `contigs` to define continious chains. Use a `:` to define multiple contigs and a `/` to define mutliple segments within a contig.\n",
        "For example:\n",
        "\n",
        "**unconditional**\n",
        "- `contigs='100'` - diffuse **monomer** of length 100\n",
        "- `contigs='50:100'` - diffuse **hetero-oligomer** of lengths 50 and 100\n",
        "- `contigs='50'` `symmetry='cyclic'` `order=2` - make two copies of the defined contig(s) and add a symmetry constraint, for **homo-oligomeric** diffusion.\n",
        "\n",
        "**binder design**\n",
        "- `contigs='A:50'` `pdb='4N5T'` - diffuse a **binder** of length 50 to chain A of defined PDB.\n",
        "- `contigs='E6-155:70-100'` `pdb='5KQV'` `hotspot='E64,E88,E96'` - diffuse a **binder** of length 70 to 100 (sampled randomly) to chain E and defined hotspot(s).\n",
        "\n",
        "**motif scaffolding**\n",
        " - `contigs='40/A163-181/40'` `pdb='5TPN'`\n",
        " - `contigs='A3-30/36/A33-68'` `pdb='6MRR'` - diffuse a loop of length 36 between two segments of defined PDB ranges.\n",
        "\n",
        "**partial diffusion**\n",
        "- `contigs=''` `pdb='6MRR'` - noise all coordinates\n",
        "- `contigs='A1-10'` `pdb='6MRR'` - keep first 10 positions fixed, noise the rest\n",
        "- `contigs='A'` `pdb='1SSC'` - fix chain A, noise the rest\n",
        "\n",
        "*hints and tips*\n",
        "- `pdb=''` leave blank to get an upload prompt\n",
        "- `contigs='50-100'` use dash to specify a range of lengths to sample from"
      ],
      "metadata": {
        "id": "DKQXlWEjIOsf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "pZQnHLuDCsZm"
      },
      "outputs": [],
      "source": [
        "#@title setup **RFdiffusion** (~3min)\n",
        "%%time\n",
        "import os, time, signal\n",
        "import sys, random, string, re\n",
        "if not os.path.isdir(\"params\"):\n",
        "  os.system(\"apt-get install aria2\")\n",
        "  os.system(\"mkdir params\")\n",
        "  # send param download into background\n",
        "  os.system(\"(\\\n",
        "  aria2c -q -x 16 https://files.ipd.uw.edu/krypton/schedules.zip; \\\n",
        "  aria2c -q -x 16 http://files.ipd.uw.edu/pub/RFdiffusion/6f5902ac237024bdd0c176cb93063dc4/Base_ckpt.pt; \\\n",
        "  aria2c -q -x 16 http://files.ipd.uw.edu/pub/RFdiffusion/e29311f6f1bf1af907f9ef9f44b8328b/Complex_base_ckpt.pt; \\\n",
        "  aria2c -q -x 16 http://files.ipd.uw.edu/pub/RFdiffusion/f572d396fae9206628714fb2ce00f72e/Complex_beta_ckpt.pt; \\\n",
        "  aria2c -q -x 16 https://storage.googleapis.com/alphafold/alphafold_params_2022-12-06.tar; \\\n",
        "  tar -xf alphafold_params_2022-12-06.tar -C params; \\\n",
        "  touch params/done.txt) &\")\n",
        "\n",
        "if not os.path.isdir(\"RFdiffusion\"):\n",
        "  print(\"installing RFdiffusion...\")\n",
        "  os.system(\"git clone https://github.com/sokrypton/RFdiffusion.git\")\n",
        "  os.system(\"pip install jedi omegaconf hydra-core icecream pyrsistent pynvml decorator\")\n",
        "  os.system(\"pip install git+https://github.com/NVIDIA/dllogger#egg=dllogger\")\n",
        "  # 17Mar2024: adding --no-dependencies to avoid installing nvidia-cuda-* dependencies\n",
        "  os.system(\"pip install --no-dependencies dgl==2.0.0 -f https://data.dgl.ai/wheels/cu121/repo.html\")\n",
        "  os.system(\"pip install --no-dependencies e3nn==0.3.3 opt_einsum_fx\")\n",
        "  os.system(\"cd RFdiffusion/env/SE3Transformer; pip install .\")\n",
        "  os.system(\"wget -qnc https://files.ipd.uw.edu/krypton/ananas\")\n",
        "  os.system(\"chmod +x ananas\")\n",
        "\n",
        "if not os.path.isdir(\"colabdesign\"):\n",
        "  print(\"installing ColabDesign...\")\n",
        "  os.system(\"pip -q install git+https://github.com/sokrypton/ColabDesign.git\")\n",
        "  os.system(\"ln -s /usr/local/lib/python3.*/dist-packages/colabdesign colabdesign\")\n",
        "\n",
        "if not os.path.isdir(\"RFdiffusion/models\"):\n",
        "  print(\"downloading RFdiffusion params...\")\n",
        "  os.system(\"mkdir RFdiffusion/models\")\n",
        "  models = [\"Base_ckpt.pt\",\"Complex_base_ckpt.pt\",\"Complex_beta_ckpt.pt\"]\n",
        "  for m in models:\n",
        "    while os.path.isfile(f\"{m}.aria2\"):\n",
        "      time.sleep(5)\n",
        "  os.system(f\"mv {' '.join(models)} RFdiffusion/models\")\n",
        "  os.system(\"unzip schedules.zip; rm schedules.zip\")\n",
        "\n",
        "if 'RFdiffusion' not in sys.path:\n",
        "  os.environ[\"DGLBACKEND\"] = \"pytorch\"\n",
        "  sys.path.append('RFdiffusion')\n",
        "\n",
        "from google.colab import files\n",
        "import json\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import display, HTML\n",
        "import ipywidgets as widgets\n",
        "import py3Dmol\n",
        "\n",
        "from inference.utils import parse_pdb\n",
        "from colabdesign.rf.utils import get_ca\n",
        "from colabdesign.rf.utils import fix_contigs, fix_partial_contigs, fix_pdb, sym_it\n",
        "from colabdesign.shared.protein import pdb_to_string\n",
        "from colabdesign.shared.plot import plot_pseudo_3D\n",
        "\n",
        "def get_pdb(pdb_code=None):\n",
        "  if pdb_code is None or pdb_code == \"\":\n",
        "    upload_dict = files.upload()\n",
        "    pdb_string = upload_dict[list(upload_dict.keys())[0]]\n",
        "    with open(\"tmp.pdb\",\"wb\") as out: out.write(pdb_string)\n",
        "    return \"tmp.pdb\"\n",
        "  elif os.path.isfile(pdb_code):\n",
        "    return pdb_code\n",
        "  elif len(pdb_code) == 4:\n",
        "    if not os.path.isfile(f\"{pdb_code}.pdb1\"):\n",
        "      os.system(f\"wget -qnc https://files.rcsb.org/download/{pdb_code}.pdb1.gz\")\n",
        "      os.system(f\"gunzip {pdb_code}.pdb1.gz\")\n",
        "    return f\"{pdb_code}.pdb1\"\n",
        "  else:\n",
        "    os.system(f\"wget -qnc https://alphafold.ebi.ac.uk/files/AF-{pdb_code}-F1-model_v3.pdb\")\n",
        "    return f\"AF-{pdb_code}-F1-model_v3.pdb\"\n",
        "\n",
        "def run_ananas(pdb_str, path, sym=None):\n",
        "  pdb_filename = f\"outputs/{path}/ananas_input.pdb\"\n",
        "  out_filename = f\"outputs/{path}/ananas.json\"\n",
        "  with open(pdb_filename,\"w\") as handle:\n",
        "    handle.write(pdb_str)\n",
        "\n",
        "  cmd = f\"./ananas {pdb_filename} -u -j {out_filename}\"\n",
        "  if sym is None: os.system(cmd)\n",
        "  else: os.system(f\"{cmd} {sym}\")\n",
        "\n",
        "  # parse results\n",
        "  try:\n",
        "    out = json.loads(open(out_filename,\"r\").read())\n",
        "    results,AU = out[0], out[-1][\"AU\"]\n",
        "    group = AU[\"group\"]\n",
        "    chains = AU[\"chain names\"]\n",
        "    rmsd = results[\"Average_RMSD\"]\n",
        "    print(f\"AnAnaS detected {group} symmetry at RMSD:{rmsd:.3}\")\n",
        "\n",
        "    C = np.array(results['transforms'][0]['CENTER'])\n",
        "    A = [np.array(t[\"AXIS\"]) for t in results['transforms']]\n",
        "\n",
        "    # apply symmetry and filter to the asymmetric unit\n",
        "    new_lines = []\n",
        "    for line in pdb_str.split(\"\\n\"):\n",
        "      if line.startswith(\"ATOM\"):\n",
        "        chain = line[21:22]\n",
        "        if chain in chains:\n",
        "          x = np.array([float(line[i:(i+8)]) for i in [30,38,46]])\n",
        "          if group[0] == \"c\":\n",
        "            x = sym_it(x,C,A[0])\n",
        "          if group[0] == \"d\":\n",
        "            x = sym_it(x,C,A[1],A[0])\n",
        "          coord_str = \"\".join([\"{:8.3f}\".format(a) for a in x])\n",
        "          new_lines.append(line[:30]+coord_str+line[54:])\n",
        "      else:\n",
        "        new_lines.append(line)\n",
        "    return results, \"\\n\".join(new_lines)\n",
        "\n",
        "  except:\n",
        "    return None, pdb_str\n",
        "\n",
        "def run(command, steps, num_designs=1, visual=\"none\"):\n",
        "\n",
        "  def run_command_and_get_pid(command):\n",
        "    pid_file = '/dev/shm/pid'\n",
        "    os.system(f'nohup {command} & echo $! > {pid_file}')\n",
        "    with open(pid_file, 'r') as f:\n",
        "      pid = int(f.read().strip())\n",
        "    os.remove(pid_file)\n",
        "    return pid\n",
        "  def is_process_running(pid):\n",
        "    try:\n",
        "      os.kill(pid, 0)\n",
        "    except OSError:\n",
        "      return False\n",
        "    else:\n",
        "      return True\n",
        "\n",
        "  run_output = widgets.Output()\n",
        "  progress = widgets.FloatProgress(min=0, max=1, description='running', bar_style='info')\n",
        "  display(widgets.VBox([progress, run_output]))\n",
        "\n",
        "  # clear previous run\n",
        "  for n in range(steps):\n",
        "    if os.path.isfile(f\"/dev/shm/{n}.pdb\"):\n",
        "      os.remove(f\"/dev/shm/{n}.pdb\")\n",
        "\n",
        "  pid = run_command_and_get_pid(command)\n",
        "  try:\n",
        "    fail = False\n",
        "    for _ in range(num_designs):\n",
        "\n",
        "      # for each step check if output generated\n",
        "      for n in range(steps):\n",
        "        wait = True\n",
        "        while wait and not fail:\n",
        "          time.sleep(0.1)\n",
        "          if os.path.isfile(f\"/dev/shm/{n}.pdb\"):\n",
        "            pdb_str = open(f\"/dev/shm/{n}.pdb\").read()\n",
        "            if pdb_str[-3:] == \"TER\":\n",
        "              wait = False\n",
        "            elif not is_process_running(pid):\n",
        "              fail = True\n",
        "          elif not is_process_running(pid):\n",
        "            fail = True\n",
        "\n",
        "        if fail:\n",
        "          progress.bar_style = 'danger'\n",
        "          progress.description = \"failed\"\n",
        "          break\n",
        "\n",
        "        else:\n",
        "          progress.value = (n+1) / steps\n",
        "          if visual != \"none\":\n",
        "            with run_output:\n",
        "              run_output.clear_output(wait=True)\n",
        "              if visual == \"image\":\n",
        "                xyz, bfact = get_ca(f\"/dev/shm/{n}.pdb\", get_bfact=True)\n",
        "                fig = plt.figure()\n",
        "                fig.set_dpi(100);fig.set_figwidth(6);fig.set_figheight(6)\n",
        "                ax1 = fig.add_subplot(111);ax1.set_xticks([]);ax1.set_yticks([])\n",
        "                plot_pseudo_3D(xyz, c=bfact, cmin=0.5, cmax=0.9, ax=ax1)\n",
        "                plt.show()\n",
        "              if visual == \"interactive\":\n",
        "                view = py3Dmol.view(js='https://3dmol.org/build/3Dmol.js')\n",
        "                view.addModel(pdb_str,'pdb')\n",
        "                view.setStyle({'cartoon': {'colorscheme': {'prop':'b','gradient': 'roygb','min':0.5,'max':0.9}}})\n",
        "                view.zoomTo()\n",
        "                view.show()\n",
        "        if os.path.exists(f\"/dev/shm/{n}.pdb\"):\n",
        "          os.remove(f\"/dev/shm/{n}.pdb\")\n",
        "      if fail:\n",
        "        progress.bar_style = 'danger'\n",
        "        progress.description = \"failed\"\n",
        "        break\n",
        "\n",
        "    while is_process_running(pid):\n",
        "      time.sleep(0.1)\n",
        "\n",
        "  except KeyboardInterrupt:\n",
        "    os.kill(pid, signal.SIGTERM)\n",
        "    progress.bar_style = 'danger'\n",
        "    progress.description = \"stopped\"\n",
        "\n",
        "def run_diffusion(contigs, path, pdb=None, iterations=50,\n",
        "                  symmetry=\"none\", order=1, hotspot=None,\n",
        "                  chains=None, add_potential=False, partial_T=\"auto\",\n",
        "                  num_designs=1, use_beta_model=False, visual=\"none\"):\n",
        "\n",
        "  full_path = f\"outputs/{path}\"\n",
        "  os.makedirs(full_path, exist_ok=True)\n",
        "  opts = [f\"inference.output_prefix={full_path}\",\n",
        "          f\"inference.num_designs={num_designs}\"]\n",
        "\n",
        "  if chains == \"\": chains = None\n",
        "\n",
        "  # determine symmetry type\n",
        "  if symmetry in [\"auto\",\"cyclic\",\"dihedral\"]:\n",
        "    if symmetry == \"auto\":\n",
        "      sym, copies = None, 1\n",
        "    else:\n",
        "      sym, copies = {\"cyclic\":(f\"c{order}\",order),\n",
        "                     \"dihedral\":(f\"d{order}\",order*2)}[symmetry]\n",
        "  else:\n",
        "    symmetry = None\n",
        "    sym, copies = None, 1\n",
        "\n",
        "  # determine mode\n",
        "  contigs = contigs.replace(\",\",\" \").replace(\":\",\" \").split()\n",
        "  is_fixed, is_free = False, False\n",
        "  fixed_chains = []\n",
        "  for contig in contigs:\n",
        "    for x in contig.split(\"/\"):\n",
        "      a = x.split(\"-\")[0]\n",
        "      if a[0].isalpha():\n",
        "        is_fixed = True\n",
        "        if a[0] not in fixed_chains:\n",
        "          fixed_chains.append(a[0])\n",
        "      if a.isnumeric():\n",
        "        is_free = True\n",
        "  if len(contigs) == 0 or not is_free:\n",
        "    mode = \"partial\"\n",
        "  elif is_fixed:\n",
        "    mode = \"fixed\"\n",
        "  else:\n",
        "    mode = \"free\"\n",
        "\n",
        "  # fix input contigs\n",
        "  if mode in [\"partial\",\"fixed\"]:\n",
        "    pdb_str = pdb_to_string(get_pdb(pdb), chains=chains)\n",
        "    if symmetry == \"auto\":\n",
        "      a, pdb_str = run_ananas(pdb_str, path)\n",
        "      if a is None:\n",
        "        print(f'ERROR: no symmetry detected')\n",
        "        symmetry = None\n",
        "        sym, copies = None, 1\n",
        "      else:\n",
        "        if a[\"group\"][0] == \"c\":\n",
        "          symmetry = \"cyclic\"\n",
        "          sym, copies = a[\"group\"], int(a[\"group\"][1:])\n",
        "        elif a[\"group\"][0] == \"d\":\n",
        "          symmetry = \"dihedral\"\n",
        "          sym, copies = a[\"group\"], 2 * int(a[\"group\"][1:])\n",
        "        else:\n",
        "          print(f'ERROR: the detected symmetry ({a[\"group\"]}) not currently supported')\n",
        "          symmetry = None\n",
        "          sym, copies = None, 1\n",
        "\n",
        "    elif mode == \"fixed\":\n",
        "      pdb_str = pdb_to_string(pdb_str, chains=fixed_chains)\n",
        "\n",
        "    pdb_filename = f\"{full_path}/input.pdb\"\n",
        "    with open(pdb_filename, \"w\") as handle:\n",
        "      handle.write(pdb_str)\n",
        "\n",
        "    parsed_pdb = parse_pdb(pdb_filename)\n",
        "    opts.append(f\"inference.input_pdb={pdb_filename}\")\n",
        "    if mode in [\"partial\"]:\n",
        "      if partial_T == \"auto\":\n",
        "        iterations = int(80 * (iterations / 200))\n",
        "      else:\n",
        "        iterations = int(partial_T)\n",
        "      opts.append(f\"diffuser.partial_T={iterations}\")\n",
        "      contigs = fix_partial_contigs(contigs, parsed_pdb)\n",
        "    else:\n",
        "      opts.append(f\"diffuser.T={iterations}\")\n",
        "      contigs = fix_contigs(contigs, parsed_pdb)\n",
        "  else:\n",
        "    opts.append(f\"diffuser.T={iterations}\")\n",
        "    parsed_pdb = None\n",
        "    contigs = fix_contigs(contigs, parsed_pdb)\n",
        "\n",
        "  if hotspot is not None and hotspot != \"\":\n",
        "    hotspot = \",\".join(hotspot.replace(\",\",\" \").split())\n",
        "    opts.append(f\"ppi.hotspot_res='[{hotspot}]'\")\n",
        "\n",
        "  # setup symmetry\n",
        "  if sym is not None:\n",
        "    sym_opts = [\"--config-name symmetry\", f\"inference.symmetry={sym}\"]\n",
        "    if add_potential:\n",
        "      sym_opts += [\"'potentials.guiding_potentials=[\\\"type:olig_contacts,weight_intra:1,weight_inter:0.1\\\"]'\",\n",
        "                   \"potentials.olig_intra_all=True\",\"potentials.olig_inter_all=True\",\n",
        "                   \"potentials.guide_scale=2\",\"potentials.guide_decay=quadratic\"]\n",
        "    opts = sym_opts + opts\n",
        "    contigs = sum([contigs] * copies,[])\n",
        "\n",
        "  opts.append(f\"'contigmap.contigs=[{' '.join(contigs)}]'\")\n",
        "  opts += [\"inference.dump_pdb=True\",\"inference.dump_pdb_path='/dev/shm'\"]\n",
        "  if use_beta_model:\n",
        "    opts += [\"inference.ckpt_override_path=./RFdiffusion/models/Complex_beta_ckpt.pt\"]\n",
        "\n",
        "  print(\"mode:\", mode)\n",
        "  print(\"output:\", full_path)\n",
        "  print(\"contigs:\", contigs)\n",
        "\n",
        "  opts_str = \" \".join(opts)\n",
        "  cmd = f\"./RFdiffusion/run_inference.py {opts_str}\"\n",
        "  print(cmd)\n",
        "\n",
        "  # RUN\n",
        "  run(cmd, iterations, num_designs, visual=visual)\n",
        "\n",
        "  # fix pdbs\n",
        "  for n in range(num_designs):\n",
        "    pdbs = [f\"outputs/traj/{path}_{n}_pX0_traj.pdb\",\n",
        "            f\"outputs/traj/{path}_{n}_Xt-1_traj.pdb\",\n",
        "            f\"{full_path}_{n}.pdb\"]\n",
        "    for pdb in pdbs:\n",
        "      with open(pdb,\"r\") as handle: pdb_str = handle.read()\n",
        "      with open(pdb,\"w\") as handle: handle.write(fix_pdb(pdb_str, contigs))\n",
        "\n",
        "  return contigs, copies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "TuRUfQJZ4vkM"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "#@title run **RFdiffusion** to generate a backbone\n",
        "name = \"test\" #@param {type:\"string\"}\n",
        "contigs = \"100\" #@param {type:\"string\"}\n",
        "pdb = \"\" #@param {type:\"string\"}\n",
        "iterations = 50 #@param [\"25\", \"50\", \"100\", \"150\", \"200\"] {type:\"raw\"}\n",
        "hotspot = \"\" #@param {type:\"string\"}\n",
        "num_designs = 1 #@param [\"1\", \"2\", \"4\", \"8\", \"16\", \"32\"] {type:\"raw\"}\n",
        "visual = \"image\" #@param [\"none\", \"image\", \"interactive\"]\n",
        "#@markdown ---\n",
        "#@markdown **symmetry** settings\n",
        "#@markdown ---\n",
        "symmetry = \"none\" #@param [\"none\", \"auto\", \"cyclic\", \"dihedral\"]\n",
        "order = 1 #@param [\"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\", \"11\", \"12\"] {type:\"raw\"}\n",
        "chains = \"\" #@param {type:\"string\"}\n",
        "add_potential = True #@param {type:\"boolean\"}\n",
        "#@markdown - `symmetry='auto'` enables automatic symmetry dectection with [AnAnaS](https://team.inria.fr/nano-d/software/ananas/).\n",
        "#@markdown - `chains=\"A,B\"` filter PDB input to these chains (may help auto-symm detector)\n",
        "#@markdown - `add_potential` to discourage clashes between chains\n",
        "#@markdown ---\n",
        "#@markdown **advanced** settings\n",
        "#@markdown ---\n",
        "partial_T = \"auto\" # @param [\"auto\", \"10\", \"20\", \"40\", \"60\", \"80\"]\n",
        "#@markdown - specify number of noising steps (only used for the partial diffusion protocol)\n",
        "use_beta_model = False #@param {type:\"boolean\"}\n",
        "#@markdown - if you are seeing lots of helices, switch to the \"beta\" params for a better SSE balance.\n",
        "\n",
        "# determine where to save\n",
        "path = name\n",
        "while os.path.exists(f\"outputs/{path}_0.pdb\"):\n",
        "  path = name + \"_\" + ''.join(random.choices(string.ascii_lowercase + string.digits, k=5))\n",
        "\n",
        "flags = {\"contigs\":contigs,\n",
        "         \"pdb\":pdb,\n",
        "         \"order\":order,\n",
        "         \"iterations\":iterations,\n",
        "         \"symmetry\":symmetry,\n",
        "         \"hotspot\":hotspot,\n",
        "         \"path\":path,\n",
        "         \"chains\":chains,\n",
        "         \"add_potential\":add_potential,\n",
        "         \"num_designs\":num_designs,\n",
        "         \"use_beta_model\":use_beta_model,\n",
        "         \"visual\":visual,\n",
        "         \"partial_T\":partial_T}\n",
        "\n",
        "for k,v in flags.items():\n",
        "  if isinstance(v,str):\n",
        "    flags[k] = v.replace(\"'\",\"\").replace('\"','')\n",
        "\n",
        "contigs, copies = run_diffusion(**flags)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "wqEi03_qi_g2"
      },
      "outputs": [],
      "source": [
        "#@title Display 3D structure {run: \"auto\"}\n",
        "animate = \"none\" #@param [\"none\", \"movie\", \"interactive\"]\n",
        "color = \"chain\" #@param [\"rainbow\", \"chain\", \"plddt\"]\n",
        "denoise = True\n",
        "dpi = 100 #@param [\"100\", \"200\", \"400\"] {type:\"raw\"}\n",
        "from colabdesign.shared.plot import pymol_color_list\n",
        "from colabdesign.rf.utils import get_ca, get_Ls, make_animation\n",
        "from string import ascii_uppercase,ascii_lowercase\n",
        "alphabet_list = list(ascii_uppercase+ascii_lowercase)\n",
        "\n",
        "def plot_pdb(num=0):\n",
        "  if denoise:\n",
        "    pdb_traj = f\"outputs/traj/{path}_{num}_pX0_traj.pdb\"\n",
        "  else:\n",
        "    pdb_traj = f\"outputs/traj/{path}_{num}_Xt-1_traj.pdb\"\n",
        "  if animate in [\"none\",\"interactive\"]:\n",
        "    hbondCutoff = 4.0\n",
        "    view = py3Dmol.view(js='https://3dmol.org/build/3Dmol.js')\n",
        "    if animate == \"interactive\":\n",
        "      pdb_str = open(pdb_traj,'r').read()\n",
        "      view.addModelsAsFrames(pdb_str,'pdb',{'hbondCutoff':hbondCutoff})\n",
        "    else:\n",
        "      pdb = f\"outputs/{path}_{num}.pdb\"\n",
        "      pdb_str = open(pdb,'r').read()\n",
        "      view.addModel(pdb_str,'pdb',{'hbondCutoff':hbondCutoff})\n",
        "    if color == \"rainbow\":\n",
        "      view.setStyle({'cartoon': {'color':'spectrum'}})\n",
        "    elif color == \"chain\":\n",
        "      for n,chain,c in zip(range(len(contigs)),\n",
        "                              alphabet_list,\n",
        "                              pymol_color_list):\n",
        "          view.setStyle({'chain':chain},{'cartoon': {'color':c}})\n",
        "    else:\n",
        "      view.setStyle({'cartoon': {'colorscheme': {'prop':'b','gradient': 'roygb','min':0.5,'max':0.9}}})\n",
        "    view.zoomTo()\n",
        "    if animate == \"interactive\":\n",
        "      view.animate({'loop': 'backAndForth'})\n",
        "    view.show()\n",
        "  else:\n",
        "    Ls = get_Ls(contigs)\n",
        "    xyz, bfact = get_ca(pdb_traj, get_bfact=True)\n",
        "    xyz = xyz.reshape((-1,sum(Ls),3))[::-1]\n",
        "    bfact = bfact.reshape((-1,sum(Ls)))[::-1]\n",
        "    if color == \"chain\":\n",
        "      display(HTML(make_animation(xyz, Ls=Ls, dpi=dpi, ref=-1)))\n",
        "    elif color == \"rainbow\":\n",
        "      display(HTML(make_animation(xyz, dpi=dpi, ref=-1)))\n",
        "    else:\n",
        "      display(HTML(make_animation(xyz, plddt=bfact*100, dpi=dpi, ref=-1)))\n",
        "\n",
        "\n",
        "if num_designs > 1:\n",
        "  output = widgets.Output()\n",
        "  def on_change(change):\n",
        "    if change['name'] == 'value':\n",
        "      with output:\n",
        "        output.clear_output(wait=True)\n",
        "        plot_pdb(change['new'])\n",
        "  dropdown = widgets.Dropdown(\n",
        "      options=[(f'{k}',k) for k in range(num_designs)],\n",
        "      value=0, description='design:',\n",
        "  )\n",
        "  dropdown.observe(on_change)\n",
        "  display(widgets.VBox([dropdown, output]))\n",
        "  with output:\n",
        "    plot_pdb(dropdown.value)\n",
        "else:\n",
        "  plot_pdb()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "rES3p-q6j4tc"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "#@title run **ProteinMPNN** to generate a sequence and **AlphaFold** to validate\n",
        "#@markdown ProteinMPNN Settings\n",
        "num_seqs = 8 #@param [\"1\", \"2\", \"4\", \"8\", \"16\", \"32\", \"64\"] {type:\"raw\"}\n",
        "mpnn_sampling_temp = 0.1 #@param [\"0.0001\", \"0.1\", \"0.15\", \"0.2\", \"0.25\", \"0.3\", \"0.5\", \"1.0\"] {type:\"raw\"}\n",
        "rm_aa = \"C\" #@param {type:\"string\"}\n",
        "use_solubleMPNN = False #@param {type:\"boolean\"}\n",
        "#@markdown - `mpnn_sampling_temp` - control diversity of sampled sequences. (higher = more diverse).\n",
        "#@markdown - `rm_aa='C'` - do not use [C]ysteines.\n",
        "#@markdown - `use_solubleMPNN` - use weights trained only on soluble proteins. See [preprint](https://www.biorxiv.org/content/10.1101/2023.05.09.540044v2).\n",
        "#@markdown\n",
        "#@markdown AlphaFold Settings\n",
        "initial_guess = False #@param {type:\"boolean\"}\n",
        "#@markdown - soft initialization with desired coordinates, see [paper](https://www.nature.com/articles/s41467-023-38328-5).\n",
        "num_recycles = 1 #@param [\"0\", \"1\", \"2\", \"3\", \"6\", \"12\"] {type:\"raw\"}\n",
        "#@markdown - for **binder** design, we recommend `initial_guess=True num_recycles=3`\n",
        "use_multimer = False #@param {type:\"boolean\"}\n",
        "#@markdown - `use_multimer` - use AlphaFold Multimer v3 params for prediction.\n",
        "\n",
        "if not os.path.isfile(\"params/done.txt\"):\n",
        "  print(\"downloading AlphaFold params...\")\n",
        "  while not os.path.isfile(\"params/done.txt\"):\n",
        "    time.sleep(5)\n",
        "\n",
        "contigs_str = \":\".join(contigs)\n",
        "opts = [f\"--pdb=outputs/{path}_0.pdb\",\n",
        "        f\"--loc=outputs/{path}\",\n",
        "        f\"--contig={contigs_str}\",\n",
        "        f\"--copies={copies}\",\n",
        "        f\"--num_seqs={num_seqs}\",\n",
        "        f\"--num_recycles={num_recycles}\",\n",
        "        f\"--rm_aa={rm_aa}\",\n",
        "        f\"--mpnn_sampling_temp={mpnn_sampling_temp}\",\n",
        "        f\"--num_designs={num_designs}\"]\n",
        "if initial_guess: opts.append(\"--initial_guess\")\n",
        "if use_multimer: opts.append(\"--use_multimer\")\n",
        "if use_solubleMPNN: opts.append(\"--use_soluble\")\n",
        "opts = ' '.join(opts)\n",
        "!python colabdesign/rf/designability_test.py {opts}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "DUNKRBNSvk6_"
      },
      "outputs": [],
      "source": [
        "#@title Display best result\n",
        "import py3Dmol\n",
        "def plot_pdb(num = \"best\"):\n",
        "  if num == \"best\":\n",
        "    with open(f\"outputs/{path}/best.pdb\",\"r\") as f:\n",
        "      # REMARK 001 design {m} N {n} RMSD {rmsd}\n",
        "      info = f.readline().strip('\\n').split()\n",
        "    num = info[3]\n",
        "  hbondCutoff = 4.0\n",
        "  view = py3Dmol.view(js='https://3dmol.org/build/3Dmol.js')\n",
        "  pdb_str = open(f\"outputs/{path}_{num}.pdb\",'r').read()\n",
        "  view.addModel(pdb_str,'pdb',{'hbondCutoff':hbondCutoff})\n",
        "  pdb_str = open(f\"outputs/{path}/best_design{num}.pdb\",'r').read()\n",
        "  view.addModel(pdb_str,'pdb',{'hbondCutoff':hbondCutoff})\n",
        "\n",
        "  view.setStyle({\"model\":0},{'cartoon':{}}) #: {'colorscheme': {'prop':'b','gradient': 'roygb','min':0,'max':100}}})\n",
        "  view.setStyle({\"model\":1},{'cartoon':{'colorscheme': {'prop':'b','gradient': 'roygb','min':0,'max':100}}})\n",
        "  view.zoomTo()\n",
        "  view.show()\n",
        "\n",
        "if num_designs > 1:\n",
        "  def on_change(change):\n",
        "    if change['name'] == 'value':\n",
        "      with output:\n",
        "        output.clear_output(wait=True)\n",
        "        plot_pdb(change['new'])\n",
        "  dropdown = widgets.Dropdown(\n",
        "    options=[\"best\"] + [str(k) for k in range(num_designs)],\n",
        "    value=\"best\",\n",
        "    description='design:',\n",
        "  )\n",
        "  dropdown.observe(on_change)\n",
        "  output = widgets.Output()\n",
        "  display(widgets.VBox([dropdown, output]))\n",
        "  with output:\n",
        "    plot_pdb(dropdown.value)\n",
        "else:\n",
        "  plot_pdb()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tVAE0BrnZoRR"
      },
      "outputs": [],
      "source": [
        "#@title Package and download results\n",
        "#@markdown If you are having issues downloading the result archive,\n",
        "#@markdown try disabling your adblocker and run this cell again.\n",
        "#@markdown  If that fails click on the little folder icon to the\n",
        "#@markdown  left, navigate to file: `name.result.zip`,\n",
        "#@markdown  right-click and select \\\"Download\\\"\n",
        "#@markdown (see [screenshot](https://pbs.twimg.com/media/E6wRW2lWUAEOuoe?format=jpg&name=small)).\n",
        "!zip -r {path}.result.zip outputs/{path}* outputs/traj/{path}*\n",
        "files.download(f\"{path}.result.zip\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oR3OdJ6UB1qb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Phase 4 .Autodock Vina**\n",
        " **Virtual Screening**\n",
        "\n",
        "This labodock notebook is designed for conducting structure-based virtual screening procedures using **Autodock Vina 1.2.5** and performing binding interaction analysis with **PLIP 2.3.0**.\n",
        "\n",
        "[![DOI](https://img.shields.io/badge/DOI-10.5281/zenodo.8246977-blue)](https://doi.org/10.5281/zenodo.8246977)\n"
      ],
      "metadata": {
        "id": "4QUORmuRB4Ik"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "---\n",
        " **01 | Setting Up Environment**\n",
        "\n",
        "Firstly, we install all the necessary libraries and packages."
      ],
      "metadata": {
        "id": "NOihW_TgC8_E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The main packages that will be installed include:\n",
        "\n",
        "+ AutoDock Vina 1.2.5 (https://vina.scripps.edu/)\n",
        "+ Condacolab 0.1.7 (https://github.com/conda-incubator/condacolab)\n",
        "+ Meeko 0.5.0 (https://github.com/forlilab/Meeko)\n",
        "+ OpenBabel 3.1.1 (https://github.com/openbabel/openbabel)\n",
        "+ PLIP 2.3.0 (https://plip-tool.biotec.tu-dresden.de/plip-web/plip/index)\n",
        "+ Py3Dmol 2.0.3 (https://pypi.org/project/py3Dmol/)\n",
        "+ Rdkit 2022.9.5 (https://github.com/rdkit/rdkit)\n",
        "+ Spyrmsd 0.6.0 (https://github.com/RMeli/spyrmsd)\n",
        "\n",
        "All the above libraries and packages are currently supported by **Python 3.10**."
      ],
      "metadata": {
        "id": "jogg4pYZDjYg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title **Install packages and dependencies**\n",
        "# @markdown Thanks to **`mamba`**, the installation takes **around 2 mins**. \\\n",
        "# @markdown It will **restart** the kernel (session).\n",
        "\n",
        "import sys\n",
        "import time\n",
        "import contextlib\n",
        "\n",
        "with open('/content/labodock_install.log', 'a') as inpt:\n",
        "    with contextlib.redirect_stdout(inpt):\n",
        "\n",
        "        # -- Start installation --\n",
        "        start = time.time()\n",
        "        !rm -r /content/sample_data\n",
        "        !wget https://github.com/ccsb-scripps/AutoDock-Vina/releases/download/v1.2.5/vina_1.2.5_linux_x86_64 -O vina\n",
        "        !wget https://raw.githubusercontent.com/RyanZR/labodock/develop/environment.yml -O environment.yml\n",
        "        !chmod u+x vina environment.yml\n",
        "\n",
        "        !pip install condacolab==0.1.8\n",
        "        import condacolab\n",
        "        condacolab.install_mambaforge()\n",
        "        !mamba env update --file environment.yml\n",
        "        end = time.time()\n",
        "        # -- End installation --\n",
        "\n",
        "        print(f'+ Time elapsed: ' + time.strftime('%Mm %Ss', time.gmtime(end - start)))"
      ],
      "metadata": {
        "cellView": "form",
        "id": "u6q428PEDiNB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title **Import Python modules**\n",
        "# @markdown This will import the necessary Python modules.\n",
        "\n",
        "# Internal Modules\n",
        "import os\n",
        "import glob\n",
        "import time\n",
        "import shutil\n",
        "\n",
        "# External modules\n",
        "import py3Dmol\n",
        "\n",
        "# Data-related\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Google Colab-related\n",
        "from google.colab import drive\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "# Docking-related\n",
        "from rdkit import Chem, RDLogger\n",
        "from rdkit.Chem import rdFMCS, AllChem, Draw\n",
        "from spyrmsd import io, rmsd\n",
        "\n",
        "# Binding interaction-related\n",
        "from plip.exchange.report import BindingSiteReport\n",
        "from plip.structure.preparation import PDBComplex\n",
        "\n",
        "print(f'+ Import completed')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "x_wF0gCaD2q5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title **Create folders**\n",
        "# @markdown Enter a **< Job Name >** to create a working directory containing:\n",
        "# @markdown + **`PROTEIN`** : Stores the target protein\n",
        "# @markdown + **`LIGAND`** : Stores the ligand to be docked\n",
        "# @markdown + **`NATIVE`** : Stores the native ligand of target protein\n",
        "# @markdown + **`DOCK`** : Stores the docking pose and scoring data\n",
        "# @markdown + **`INTERACTION`** : Stores the binding interaction data\n",
        "\n",
        "Job_name = '7N3N' # @param {type: 'string'}\n",
        "\n",
        "invalid_chars = '^<>/\\{}[]~`$ '\n",
        "assert Job_name, 'Do not leave this blank.'\n",
        "assert not set(invalid_chars).intersection(Job_name), 'Disallowed characters.'\n",
        "\n",
        "DIR = os.getcwd()\n",
        "WRK_DIR = os.path.join(DIR, Job_name)\n",
        "PRT_FLD = os.path.join(WRK_DIR, 'PROTEIN')\n",
        "LIG_FLD = os.path.join(WRK_DIR, 'LIGAND')\n",
        "NTV_FLD = os.path.join(WRK_DIR, 'NATIVE')\n",
        "DCK_FLD = os.path.join(WRK_DIR, 'DOCKING')\n",
        "INT_FLD = os.path.join(WRK_DIR, 'INTERACTION')\n",
        "\n",
        "folders = [WRK_DIR, PRT_FLD, LIG_FLD, NTV_FLD, DCK_FLD, INT_FLD]\n",
        "\n",
        "for folder in folders:\n",
        "    if os.path.exists(folder):\n",
        "        print(f'+ Folder existed: {folder}')\n",
        "    else:\n",
        "        os.mkdir(folder)\n",
        "        print(f'+ Folder created: {folder}')"
      ],
      "metadata": {
        "id": "b4-oQ3dQD6lB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title **Set up utilities**\n",
        "# @markdown This creates important custom functions and methods for later\n",
        "# @markdown docking and binding interaction study.\n",
        "\n",
        "%alias vina ./vina\n",
        "\n",
        "#############################################\n",
        "# Suppress Warnings\n",
        "\n",
        "RDLogger.DisableLog('rdApp.warning')\n",
        "\n",
        "#############################################\n",
        "# Grid Box Calculation Methods\n",
        "\n",
        "class GridBox:\n",
        "\n",
        "    ranges = tuple[list[float], list[float], list[float]]\n",
        "    coords = tuple[float, float, float]\n",
        "    center_bxsize = tuple[tuple[float, float, float], tuple[float, float, float]]\n",
        "\n",
        "    def __init__(self, inpt_file: str) -> None:\n",
        "        self.inpt = open(inpt_file, 'r')\n",
        "        self.data = self.inpt.read()\n",
        "        self.cmol = Chem.MolFromPDBBlock(self.data)\n",
        "        self.conf = self.cmol.GetConformer()\n",
        "        self.ntom = self.cmol.GetNumAtoms()\n",
        "        self.inpt.close()\n",
        "\n",
        "    def update_gridbox(self, mol_block: str) -> None:\n",
        "        self.cmol = Chem.MolFromPDBBlock(mol_block)\n",
        "        self.conf = self.cmol.GetConformer()\n",
        "        self.ntom = self.cmol.GetNumAtoms()\n",
        "\n",
        "    def compute_coords(self) -> ranges:\n",
        "        x_coord = [self.conf.GetAtomPosition(c).x for c in range(self.ntom)]\n",
        "        y_coord = [self.conf.GetAtomPosition(c).y for c in range(self.ntom)]\n",
        "        z_coord = [self.conf.GetAtomPosition(c).z for c in range(self.ntom)]\n",
        "        return x_coord, y_coord, z_coord\n",
        "\n",
        "    def compute_ranges(self) -> ranges:\n",
        "        x, y, z = self.compute_coords()\n",
        "        x_range = [min(x), max(x)]\n",
        "        y_range = [min(y), max(y)]\n",
        "        z_range = [min(z), max(z)]\n",
        "        return x_range, y_range, z_range\n",
        "\n",
        "    def compute_center(self, use_range: bool = True) -> coords:\n",
        "        x, y, z = self.compute_ranges() if use_range else self.compute_coords()\n",
        "        x_center = round(np.mean(x), 3)\n",
        "        y_center = round(np.mean(y), 3)\n",
        "        z_center = round(np.mean(z), 3)\n",
        "        return x_center, y_center, z_center\n",
        "\n",
        "    def generate_res_molblock(self, residues_list: list[str]) -> str:\n",
        "        res_lines = [line for line in self.data.split('\\n')\n",
        "                     if line[22:26].lstrip() in residues_list\n",
        "                     and 'END' not in line]\n",
        "        res_block = '\\n'.join(res_lines)\n",
        "        return res_block\n",
        "\n",
        "    def labox(self, scale: float = 2.0) -> coords:\n",
        "        xr, yr, zr = self.compute_ranges()\n",
        "        center = self.compute_center()\n",
        "        bxsize = (round(abs(xr[0] - xr[1]) * scale, 3),\n",
        "                  round(abs(yr[0] - yr[1]) * scale, 3),\n",
        "                  round(abs(zr[0] - zr[1]) * scale, 3))\n",
        "        return center, bxsize\n",
        "\n",
        "    def eboxsize(self, gy_box_ratio: float = 0.23, modified: bool = False) -> center_bxsize:\n",
        "        xc, yc, zc = self.compute_coords()\n",
        "        center = self.compute_center(modified)\n",
        "        distsq = [(x-center[0])**2 + (y-center[1])**2 + (z-center[2])**2\n",
        "                  for x, y, z in zip(xc, yc, zc)]\n",
        "        bxsize = (round(np.sqrt(sum(distsq) / len(xc)) / gy_box_ratio, 3),) * 3\n",
        "        return center, bxsize\n",
        "\n",
        "    def autodock_grid(self) -> center_bxsize:\n",
        "        xr, yr, zr = self.compute_ranges()\n",
        "        center = self.compute_center()\n",
        "        bxsize = (22.5, 22.5, 22.5)\n",
        "        return center, bxsize\n",
        "\n",
        "    def defined_by_res(self, residue_number: str, scale: float = 1.25) -> center_bxsize:\n",
        "        res_list = residue_number.replace(',', ' ').split()\n",
        "        res_block = self.generate_res_molblock(res_list)\n",
        "        self.update_gridbox(res_block)\n",
        "        return self.labox(scale=scale)\n",
        "\n",
        "#############################################\n",
        "# RMSD Calculation Methods\n",
        "\n",
        "class ComputeRMSD:\n",
        "\n",
        "    def __init__(self) -> None:\n",
        "        self.MCS_mol = None\n",
        "        self.MCS_png = None\n",
        "\n",
        "    def load_molecule(self, inpt_file: str, remove_Hs: bool = True) -> tuple:\n",
        "        molecule = io.loadmol(inpt_file)\n",
        "        molecule.strip() if remove_Hs else None\n",
        "        name = os.path.basename(inpt_file).split('.')[0]\n",
        "        coor = molecule.coordinates\n",
        "        anum = molecule.atomicnums\n",
        "        mtrx = molecule.adjacency_matrix\n",
        "        cmol = Chem.MolFromPDBFile(inpt_file)\n",
        "        return name, coor, anum, mtrx, cmol\n",
        "\n",
        "    def mol_to_png(self, mol: object) -> object:\n",
        "        legend = 'Maximum Common Substructure'\n",
        "        png = Draw.MolToImage(mol, legend=legend)\n",
        "        return png\n",
        "\n",
        "    def find_MCS(self, ref: tuple, lig: tuple) -> object:\n",
        "        if self.MCS_mol is None:\n",
        "            MCS_obj = rdFMCS.FindMCS([ref[4], lig[4]])\n",
        "            MCS_mol = Chem.MolFromSmarts(MCS_obj.smartsString)\n",
        "            MCS_png = self.mol_to_png(MCS_mol)\n",
        "            self.MCS_mol = MCS_mol\n",
        "            self.MCS_png = MCS_png\n",
        "        return self.MCS_mol\n",
        "\n",
        "    def hung_RMSD(self, ref: tuple, lig: tuple) -> float:\n",
        "        try:\n",
        "            hRMSD = round(rmsd.hrmsd(ref[1], lig[1], ref[2], lig[2]), 3)\n",
        "        except:\n",
        "            hRMSD = 'ERROR'\n",
        "        return hRMSD\n",
        "\n",
        "    def symm_RMSD(self, ref: tuple, lig: tuple, minimise: bool = False) -> float:\n",
        "        try:\n",
        "            sRMSD = round(rmsd.symmrmsd(ref[1], lig[1], ref[2], lig[2], ref[3], lig[3], minimize=minimise), 3)\n",
        "        except:\n",
        "            sRMSD = 'ERROR'\n",
        "        return sRMSD\n",
        "\n",
        "    def labo_RMSD(self, ref: tuple, lig: tuple) -> float:\n",
        "        mol_substr = self.find_MCS(ref, lig)\n",
        "        ref_substr = ref[4].GetSubstructMatch(mol_substr)\n",
        "        lig_substr = lig[4].GetSubstructMatch(mol_substr)\n",
        "\n",
        "        distsq = []\n",
        "        for ref_atom, lig_atom in zip(ref_substr, lig_substr):\n",
        "            ref_pos = ref[4].GetConformer().GetAtomPosition(ref_atom)\n",
        "            lig_pos = lig[4].GetConformer().GetAtomPosition(lig_atom)\n",
        "            ref_coord = np.array((ref_pos.x, ref_pos.y, ref_pos.z))\n",
        "            lig_coord = np.array((lig_pos.x, lig_pos.y, lig_pos.z))\n",
        "            coo_dist = np.linalg.norm(ref_coord - lig_coord)\n",
        "            distsq.append(coo_dist ** 2)\n",
        "\n",
        "        try:\n",
        "            lRMSD = round(np.sqrt(sum(distsq)/len(distsq)), 3)\n",
        "        except:\n",
        "            lRMSD = 'ERROR'\n",
        "        return lRMSD\n",
        "\n",
        "    def rmsd_report(self,\n",
        "                    ref: tuple,\n",
        "                    lig: tuple,\n",
        "                    lRMSD: bool = True,\n",
        "                    hRMSD: bool = True,\n",
        "                    sRMSD: bool = True\n",
        "                    ) -> dict[str: list[float]]:\n",
        "        report = {}\n",
        "        report['NAME'] = [lig[0]]\n",
        "        report['LABO_RMSD'] = [self.labo_RMSD(ref, lig)] if lRMSD else None\n",
        "        report['HUNG_RMSD'] = [self.hung_RMSD(ref, lig)] if hRMSD else None\n",
        "        report['SYMM_RMSD'] = [self.symm_RMSD(ref, lig)] if sRMSD else None\n",
        "        report = {k: v for k, v in report.items() if v is not None}\n",
        "        return report\n",
        "\n",
        "#############################################\n",
        "# AA Consntant and Bond Colour Dictionary\n",
        "\n",
        "# Kyte and Doolittle Hydropathy Scale (1982)\n",
        "AA_HB = {'ALA':  1.8, 'ARG': -4.5, 'ASN': -3.5, 'ASP': -3.5, 'CYS':  2.5,\n",
        "         'GLN': -3.5, 'GLU': -3.5, 'GLY': -0.4, 'HIS': -3.2, 'ILE':  4.5,\n",
        "         'LEU':  3.8, 'LYS': -3.9, 'MET':  1.9, 'PHE':  2.8, 'PRO': -1.6,\n",
        "         'SER': -0.8, 'THR': -0.7, 'TRP': -0.9, 'TYR': -1.3, 'VAL':  4.2}\n",
        "\n",
        "# University of Calgary PI Scale\n",
        "AA_PI = {'ALA':  6.0, 'ARG': 10.76, 'ASN': 5.41, 'ASP': 2.77, 'CYS': 5.07,\n",
        "         'GLN': 5.65, 'GLU':  3.22, 'GLY': 5.97, 'HIS': 7.59, 'ILE': 6.02,\n",
        "         'LEU': 5.98, 'LYS':  9.74, 'MET': 5.74, 'PHE': 5.48, 'PRO':  6.3,\n",
        "         'SEC': 5.68, 'SER':  5.68, 'THR':  5.6, 'TRP': 5.89, 'TYR': 5.66,\n",
        "         'VAL': 5.96}\n",
        "\n",
        "BOND_COL = {'HYDROPHOBIC': ['0x59e382', 'GREEN'],\n",
        "            'HBOND': ['0x59bee3', 'LIGHT BLUE'],\n",
        "            'WATERBRIDGE': ['0x4c4cff', 'BLUE'],\n",
        "            'SALTBRIDGE': ['0xefd033', 'YELLOW'],\n",
        "            'PISTACKING': ['0xb559e3', 'PURPLE'],\n",
        "            'PICATION': ['0xe359d8', 'VIOLET'],\n",
        "            'HALOGEN': ['0x59bee3', 'LIGHT BLUE'],\n",
        "            'METAL':['0xe35959', 'ORANGE']}\n",
        "\n",
        "#############################################\n",
        "# AA-to-Colour Converter Function\n",
        "\n",
        "def sequential_gradient(value: float,\n",
        "                        min_value: float,\n",
        "                        max_value: float,\n",
        "                        targ_colour: str = '00ff00',\n",
        "                        interpolation: float = 0.0\n",
        "                        ) -> str:\n",
        "    norm_val = (value - min_value) / (max_value - min_value)\n",
        "\n",
        "    rgb = tuple(int(targ_colour[d:d+2], 16) for d in (0, 2, 4))\n",
        "    r = int(255 - (255 - rgb[0]) * (1 - interpolation) * norm_val)\n",
        "    g = int(255 - (255 - rgb[1]) * (1 - interpolation) * norm_val)\n",
        "    b = int(255 - (255 - rgb[2]) * (1 - interpolation) * norm_val)\n",
        "\n",
        "    hex_code = f'#{r:02x}{g:02x}{b:02x}'\n",
        "    return hex_code\n",
        "\n",
        "def diverging_gradient(value: float,\n",
        "                       min_value: float,\n",
        "                       max_value: float,\n",
        "                       base_colour: str = 'ff0000',\n",
        "                       targ_colour: str = '0000ff',\n",
        "                       interpolation: float = 0.3\n",
        "                       ) -> str:\n",
        "    norm_val = (value - min_value) / (max_value - min_value)\n",
        "\n",
        "    white = (255, 255, 255)\n",
        "    rgb_A = tuple(int(base_colour[d:d+2], 16) for d in (0, 2, 4))\n",
        "    rgb_B = tuple(int(targ_colour[d:d+2], 16) for d in (0, 2, 4))\n",
        "\n",
        "    if norm_val < 0.5 - interpolation / 2:\n",
        "        factor = norm_val / (0.5 - interpolation / 2)\n",
        "        r = int(rgb_A[0] + (white[0] - rgb_A[0]) * factor)\n",
        "        g = int(rgb_A[1] + (white[1] - rgb_A[1]) * factor)\n",
        "        b = int(rgb_A[2] + (white[2] - rgb_A[2]) * factor)\n",
        "    elif norm_val > 0.5 + interpolation / 2:\n",
        "        factor = (norm_val - 0.5 - interpolation / 2) / (0.5 - interpolation / 2)\n",
        "        r = int(white[0] + (rgb_B[0] - white[0]) * factor)\n",
        "        g = int(white[1] + (rgb_B[1] - white[1]) * factor)\n",
        "        b = int(white[2] + (rgb_B[2] - white[2]) * factor)\n",
        "    else:\n",
        "        r, g, b = white\n",
        "\n",
        "    hex_code = f'#{r:02x}{g:02x}{b:02x}'\n",
        "    return hex_code\n",
        "\n",
        "def a2c_converter(aa_map: dict, grad_func: 'function') -> dict:\n",
        "    min_value = min(aa_map.values())\n",
        "    max_value = max(aa_map.values())\n",
        "    aa_dict = {aa: grad_func(value, min_value, max_value)\n",
        "               for aa, value in aa_map.items()}\n",
        "    return aa_dict\n",
        "\n",
        "#############################################\n",
        "# Built-in Styling Function\n",
        "\n",
        "def builtin_style(style: str, opacity: float = 1.0) -> dict:\n",
        "    match style:\n",
        "        case _ if any(kw in style for kw in ('Carbon', 'chain', 'ssJmol', 'ssPyMol')):\n",
        "            style_dict = {'colorscheme': style}\n",
        "        case 'hydrophobicity':\n",
        "            style_dict = {'colorscheme': {\n",
        "                'prop': 'resn', 'map': a2c_converter(AA_HB, sequential_gradient)}}\n",
        "        case 'isoelectric points':\n",
        "            style_dict = {'colorscheme': {\n",
        "                'prop': 'resn', 'map': a2c_converter(AA_PI, diverging_gradient)}}\n",
        "        case 'b factor':\n",
        "            style_dict = {'colorscheme': {\n",
        "                'prop': 'b', 'gradient': 'rwb', 'min': 90, 'max': 50}}\n",
        "        case _:\n",
        "            style_dict = {'color': style}\n",
        "\n",
        "    style_dict.update({'opacity': opacity, 'singleBonds': False})\n",
        "    return style_dict\n",
        "\n",
        "#############################################\n",
        "# Built-in Colour Scale Function\n",
        "\n",
        "def colour_scale(aa_map: dict, grad_func: 'function') -> None:\n",
        "    min_value = min(aa_map.values())\n",
        "    max_value = max(aa_map.values())\n",
        "\n",
        "    linear_values = np.linspace(min_value, max_value, 100)\n",
        "    colours = [grad_func(value, min_value, max_value)\n",
        "               for value in linear_values]\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(4.85, 0.25))\n",
        "    norm_value = plt.Normalize(min_value, max_value)\n",
        "    colour_map = plt.cm.colors.ListedColormap(colours)\n",
        "    scalar_map = plt.cm.ScalarMappable(norm_value, colour_map)\n",
        "    scalar_map.set_array([])\n",
        "\n",
        "    cscale = plt.colorbar(scalar_map, ax, orientation='horizontal')\n",
        "    cscale.set_ticks([min_value, max_value])\n",
        "\n",
        "def show_cscale(rept_info: dict, surf_info: dict) -> None:\n",
        "\n",
        "    def cs_selector() -> str:\n",
        "        if any(surf_info):\n",
        "            style = [*surf_info.values()][0]\n",
        "        elif any(rept_info):\n",
        "            style = [*rept_info.values()][0]\n",
        "        else:\n",
        "            style = None\n",
        "        return style\n",
        "\n",
        "    def cs_display(style: str):\n",
        "        if style == 'hydrophobicity':\n",
        "            label_title(style, 'Less', 'More')\n",
        "            colour_scale(AA_HB, sequential_gradient)\n",
        "        elif style == 'isoelectric points':\n",
        "            label_title(style, 'Acid', 'Base')\n",
        "            colour_scale(AA_PI, diverging_gradient)\n",
        "        else:\n",
        "            pass\n",
        "\n",
        "    def label_title(text: str, min: str, max: str) -> None:\n",
        "        print(f'-' * 55)\n",
        "        print(f'{min}{text.upper():^47}{max}')\n",
        "        print(f'-' * 55)\n",
        "\n",
        "    cs_display(cs_selector())\n",
        "\n",
        "#############################################\n",
        "# Other Functions\n",
        "\n",
        "def extract_config(inpt_file: str) -> tuple:\n",
        "    with open(inpt_file, 'r') as inpt:\n",
        "        data = [line.split() for line in inpt.readlines()]\n",
        "    center = (float(data[0][2]), float(data[1][2]), float(data[2][2]))\n",
        "    bxsize = (float(data[4][2]), float(data[5][2]), float(data[6][2]))\n",
        "    return center, bxsize\n",
        "\n",
        "def interaction_dict(inpt_file: str, interactions: str = '', usage: str = 'view' or 'lbsp') -> dict:\n",
        "\n",
        "    usg_map = {'lbsp': 0, 'view': 1}\n",
        "\n",
        "    def filter_df(int_df: pd.DataFrame, interactions: list = []) -> pd.DataFrame:\n",
        "        int_df = int_df[int_df['BOND'].isin(interactions)] if interactions else int_df\n",
        "        return int_df\n",
        "\n",
        "    def s2f_dict(item: dict) -> dict:\n",
        "        return {key: tuple(float(val) for val in value[1:-1].split(','))\n",
        "                for key, value in item.items()}\n",
        "\n",
        "    def b2c_dict(item: dict) -> dict:\n",
        "        return {key: BOND_COL[val][usg_map[usage]] for key, val in item.items()}\n",
        "\n",
        "    intrxn = interactions.replace(',', ' ').split()\n",
        "    inter_df = pd.read_csv(inpt_file)\n",
        "    int_dict = filter_df(inter_df, intrxn).to_dict()\n",
        "    int_dict['LIGCOO'] = s2f_dict(int_dict['LIGCOO'])\n",
        "    int_dict['PROTCOO'] = s2f_dict(int_dict['PROTCOO'])\n",
        "    int_dict['COLOR'] = b2c_dict(int_dict['BOND'])\n",
        "\n",
        "    return int_dict\n",
        "\n",
        "def find_midpoint(coords: list) -> tuple[float, float, float]:\n",
        "    return tuple(round(coord, 3) for coord in np.mean(coords, axis=0))\n",
        "\n",
        "#############################################\n",
        "# LaboSpace Viewer\n",
        "\n",
        "class LaboSpace:\n",
        "\n",
        "    residue_style = {\n",
        "        'stick':\n",
        "         {'colorscheme': 'orangeCarbon', 'radius': 0.15}}\n",
        "    residue_label = {\n",
        "        'alignment': 'bottomLeft',\n",
        "        'showBackground': False,\n",
        "        'inFront': True,\n",
        "        'fontSize': 14,\n",
        "        'fontColor': '0x000000',\n",
        "        'screenOffset': {'x': 25, 'y': 25}}\n",
        "    atom_label = {\n",
        "        'alignment': 'bottomLeft',\n",
        "        'showBackground': False,\n",
        "        'inFront': True,\n",
        "        'fontSize': 14,\n",
        "        'fontColor': '0x000000',\n",
        "        'screenOffset': {'x': 10, 'y': 10}}\n",
        "\n",
        "    def __init__(self, vw: int = 500, vh: int = 500) -> None:\n",
        "        self.mview = py3Dmol.view(width=vw, height=vh)\n",
        "        self.count = -1\n",
        "        self.residues = []\n",
        "\n",
        "    def read_moldata(self, inpt_file: str) -> str:\n",
        "        inpt = open(inpt_file, 'r')\n",
        "        data = inpt.read()\n",
        "        inpt.close()\n",
        "        return data\n",
        "\n",
        "    def load_receptor(self, inpt_file: str) -> object:\n",
        "        data = self.read_moldata(inpt_file)\n",
        "        self.mview.addModel(data, 'pdb')\n",
        "        self.count += 1\n",
        "        return self\n",
        "\n",
        "    def load_ligand(self, inpt_file: str) -> object:\n",
        "        data = self.read_moldata(inpt_file)\n",
        "        self.mview.addModel(data)\n",
        "        self.count += 1\n",
        "        return self\n",
        "\n",
        "    def set_style(self,\n",
        "                  show_represent: bool = True,\n",
        "                  represent_type: str = 'cartoon',\n",
        "                  represent_style: dict = {}\n",
        "                  ) -> object:\n",
        "        if show_represent:\n",
        "            self.mview.setStyle(\n",
        "                {'model': self.count},\n",
        "                {represent_type: represent_style})\n",
        "        else:\n",
        "            self.mview.setStyle(\n",
        "                {'model': self.count},\n",
        "                {})\n",
        "        return self\n",
        "\n",
        "    def add_style(self,\n",
        "                  show_represent: bool = True,\n",
        "                  represent_style: dict = {}\n",
        "                  ) -> object:\n",
        "        if show_represent:\n",
        "            self.mview.addStyle(\n",
        "                {'model': self.count},\n",
        "                represent_style)\n",
        "        return self\n",
        "\n",
        "    def add_residues(self,\n",
        "                     show_residues: bool = True,\n",
        "                     residue_number: str = ''\n",
        "                     ) -> object:\n",
        "        if show_residues and residue_number:\n",
        "            res = residue_number.replace(',', ' ').split()\n",
        "            self.residues.extend(list(set(res)))\n",
        "            self.mview.addStyle(\n",
        "                {'and': [{'model': self.count}, {'resi': self.residues}]},\n",
        "                self.residue_style)\n",
        "            self.mview.addResLabels(\n",
        "                {'and': [{'model': self.count}, {'resi': self.residues}]},\n",
        "                self.residue_label)\n",
        "        return self\n",
        "\n",
        "    def add_surface(self,\n",
        "                    show_surface: bool = True,\n",
        "                    surface_type: str = 'SES',\n",
        "                    surface_style: dict = {}\n",
        "                    ) -> object:\n",
        "        if show_surface:\n",
        "            self.mview.addSurface(\n",
        "                surface_type,\n",
        "                surface_style,\n",
        "                {'model': self.count})\n",
        "        return self\n",
        "\n",
        "    def add_gridbox(self,\n",
        "                    show_gridbox: bool,\n",
        "                    center: list[float],\n",
        "                    bxsize: list[float]\n",
        "                    ) -> object:\n",
        "        if show_gridbox:\n",
        "            bxi, byi, bzi = center\n",
        "            bxf, byf, bzf = bxsize\n",
        "            self.mview.addBox({\n",
        "                'center': {'x': bxi, 'y': byi, 'z': bzi},\n",
        "                'dimensions': {'w': bxf, 'h': byf, 'd': bzf},\n",
        "                'color': 'skyBlue',\n",
        "                'opacity': 0.6})\n",
        "            self.mview.addLabel(\n",
        "                f'center: {bxi:>8}, {byi:>8}, {bzi:>8}',\n",
        "                {'showBackground': False,\n",
        "                 'fontSize': 14,\n",
        "                 'fontColor': '0x000000',\n",
        "                 'useScreen': True,\n",
        "                 'screenOffset': {'x': 15, 'y': 0}})\n",
        "            self.mview.addLabel(\n",
        "                f'bxsize: {bxf:>8}, {byf:>8}, {bzf:>8}',\n",
        "                {'showBackground': False,\n",
        "                 'fontSize': 14,\n",
        "                 'fontColor': '0x000000',\n",
        "                 'useScreen': True,\n",
        "                 'screenOffset': {'x': 15, 'y': -20}})\n",
        "        return self\n",
        "\n",
        "    def add_interaction(self,\n",
        "                        interaction_file: str,\n",
        "                        show_interaction: bool = True,\n",
        "                        select_interaction: list = []\n",
        "                        ) -> object:\n",
        "        if show_interaction:\n",
        "            int_dict = interaction_dict(interaction_file, select_interaction, 'lbsp')\n",
        "            dist = int_dict['DIST'].values()\n",
        "            bond = int_dict['BOND'].values()\n",
        "            resn = int_dict['RESNR'].values()\n",
        "            ligcoo = int_dict['LIGCOO'].values()\n",
        "            prtcoo = int_dict['PROTCOO'].values()\n",
        "            color = int_dict['COLOR'].values()\n",
        "\n",
        "            int_res = list(set(resn) - set(self.residues))\n",
        "            self.residues.extend(int_res)\n",
        "            self.mview.addStyle(\n",
        "                {'and': [{'model': 0}, {'resi': int_res}]},\n",
        "                self.residue_style)\n",
        "            self.mview.addResLabels(\n",
        "                {'and': [{'model': 0}, {'resi': int_res}]},\n",
        "                self.residue_label)\n",
        "\n",
        "            for dis, col, lig, prt in zip(dist, color, ligcoo, prtcoo):\n",
        "                mid = find_midpoint([lig, prt])\n",
        "                self.mview.addCylinder(\n",
        "                    {'start': {'x': lig[0], 'y': lig[1], 'z': lig[2]},\n",
        "                     'end': {'x': prt[0], 'y': prt[1], 'z': prt[2]},\n",
        "                     'radius': 0.05,\n",
        "                     'fromCap': 1,\n",
        "                     'toCap': 1,\n",
        "                     'color': col,\n",
        "                     'dashed': True})\n",
        "                self.mview.addLabel(\n",
        "                    str(dis) + ' Å',\n",
        "                    {'position': {'x': mid[0], 'y': mid[1], 'z': mid[2]},\n",
        "                     'alignment': 'bottomLeft',\n",
        "                     'inFront': False,\n",
        "                     'backgroundColor': col,\n",
        "                     'fontSize': 10,\n",
        "                     'screenOffset': {'x': 10, 'y': 10}})\n",
        "        return self\n",
        "\n",
        "    def label_atoms(self, show_label: bool = False) -> object:\n",
        "        # WARNING: Avoid applying on protein !!!\n",
        "        if show_label:\n",
        "            self.mview.addPropertyLabels(\n",
        "                'atom',\n",
        "                {'model': self.count},\n",
        "                self.atom_label)\n",
        "        return self\n",
        "\n",
        "    def view_space(self,\n",
        "                   zoom_model: int = -1,\n",
        "                   slab_view: bool = False,\n",
        "                   slab_model: int = -1,\n",
        "                   background_colour: str = '0xFFFFFF'\n",
        "                   ) -> None:\n",
        "        self.mview.setBackgroundColor(background_colour)\n",
        "        self.mview.setProjection('orthographic')\n",
        "        self.mview.zoomTo({'model': zoom_model})\n",
        "        self.mview.fitSlab({'model': slab_model}) if slab_view else None\n",
        "        self.mview.show()\n",
        "\n",
        "print(f'+ Methods and functions successfully built')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "QevlVuMREht5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "---\n",
        " **02 | Preparing the Receptor**\n",
        "\n",
        "In this step, we lay the groundwork for virtual screening by preparing the protein of interest. We will obtain the protein's crystal structure in **`pdb`** format from the [RCSB Protein Data Bank (PDB)](https://www.rcsb.org). Then, we clean the structure by extraction method and seperate its existing subunits into individual files. Finally, we parameterise our target strucutre to generate the **`pdbqt`** file required for docking."
      ],
      "metadata": {
        "id": "A3asahmWFAXJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title **Download protein PDB file**\n",
        "# @markdown Enter the **< Accession ID >** to download the protein of interest.\n",
        "\n",
        "Accession_ID = '7N3N' # @param {type: 'string'}\n",
        "\n",
        "PDB_pdb = Accession_ID.upper() + '.pdb'\n",
        "PDB_pdb_pFile = os.path.join(PRT_FLD, PDB_pdb)\n",
        "Accession_ID_url = 'http://files.rcsb.org/download/' + PDB_pdb\n",
        "\n",
        "!wget {Accession_ID_url} -O {PDB_pdb_pFile} -q\n",
        "print(f'+ PDB downloaded: {PDB_pdb} > PROTEIN folder')\n",
        "print(f'+ RCSB PDB link: https://www.rcsb.org/structure/{Accession_ID}')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "xepkbOp9E3p7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title **Clean protein structure and extract subunits**\n",
        "# @markdown This generates a **clean** protein structure containing all the subunit(s). \\\n",
        "# @markdown The subunits are then extracted into individual **`pdb`** files. \\\n",
        "# @markdown *Note: `Subunits` and `Chains` are interchangeable to describe the\n",
        "# @markdown multiple polypeptides that made up the protein.*\n",
        "\n",
        "def oupt_parse(inpt_file: str) -> tuple:\n",
        "    name = os.path.basename(inpt_file).split('.')[0]\n",
        "    path = os.path.dirname(inpt_file)\n",
        "    dirn = os.path.basename(path)\n",
        "    return name, dirn, path\n",
        "\n",
        "def ter_line(asn: str, resn: str, chid: str, resi: str) -> str:\n",
        "    return f'TER   {asn}      {resn} {chid}{resi:>4} {\" \"*54}\\n'\n",
        "\n",
        "def extract_protein(inpt_file: str, oupt_file: str) -> None:\n",
        "    oupt_name, oupt_dirn, oupt_path = oupt_parse(oupt_file)\n",
        "    with open(inpt_file, 'r') as inpt, \\\n",
        "         open(oupt_file , 'w') as oupt:\n",
        "        for line in inpt:\n",
        "            record = line.split()[0]\n",
        "            if 'ATOM' in record:\n",
        "                oupt.write(line)\n",
        "    print(f'+ Protein extracted: {oupt_name}.pdb > {oupt_dirn} folder')\n",
        "\n",
        "def extract_chains(inpt_file: str) -> None:\n",
        "    inpt_name, oupt_dirn, oupt_path = oupt_parse(inpt_file)\n",
        "    with open(inpt_file, 'r') as inpt:\n",
        "        data = inpt.readlines()\n",
        "\n",
        "    chid = sorted(set(line[21:22] for line in data))\n",
        "    chid_leng = len(chid)\n",
        "    chid_list = ', '.join(chid)\n",
        "    print(f'+ Chains detected: {chid_leng} ({chid_list})')\n",
        "\n",
        "    for id in chid:\n",
        "        oupt_name = inpt_name + '_' + id\n",
        "        oupt_file = os.path.join(oupt_path, oupt_name + '.pdb')\n",
        "        with open(oupt_file, 'w') as oupt:\n",
        "            for line in data:\n",
        "                if line[21:22] in id:\n",
        "                    oupt.write(line)\n",
        "                    asn = f'{int(line[6:11])+1:>5}'\n",
        "                    resn = line[17:20]\n",
        "                    resi = line[22:26]\n",
        "            oupt.write(ter_line(asn, resn, id, resi))\n",
        "            oupt.write('END')\n",
        "        print(f'+ Chain extracted: {oupt_name}.pdb > {oupt_dirn} folder')\n",
        "\n",
        "PDB_prot = Accession_ID + '_prot'\n",
        "PDB_prot_pdb = PDB_prot + '.pdb'\n",
        "PDB_prot_pdb_pFile = os.path.join(PRT_FLD, PDB_prot_pdb)\n",
        "\n",
        "extract_protein(PDB_pdb_pFile, PDB_prot_pdb_pFile)\n",
        "extract_chains(PDB_prot_pdb_pFile)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "0aPhcNaSGB9f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title **Visualise 3D protein structure**\n",
        "# @markdown Enter the **< Protein >** to be viewed.\n",
        "\n",
        "View = '7N3N_prot_A' # @param {type: 'string'}\n",
        "Representation_type = 'cartoon' # @param ['cartoon', 'cross', 'line', 'sphere', 'stick']\n",
        "Representation_style = 'white' # @param ['chain', 'white', 'whiteCarbon', 'ssJmol', 'ssPyMol', 'b factor', 'hydrophobicity', 'isoelectric points']\n",
        "Representation_opacity = 1 # @param {type:'slider', min:0, max:1, step:0.1}\n",
        "Residue_number = '' # @param {type:'string'}\n",
        "Surface_type = 'SES' # @param ['VDW', 'SAS', 'SES', 'MS']\n",
        "Surface_style = 'hydrophobicity' # @param ['chain', 'white', 'whiteCarbon', 'ssJmol', 'ssPyMol', 'b factor', 'hydrophobicity', 'isoelectric points']\n",
        "Surface_opacity = 1 # @param {type:'slider', min:0, max:1, step:0.1}\n",
        "Show_representation = True # @param {type:'boolean'}\n",
        "Show_residue = False # @param {type:'boolean'}\n",
        "Show_surface = False # @param {type:'boolean'}\n",
        "\n",
        "PROT_view_pFile = os.path.join(PRT_FLD, View + '.pdb')\n",
        "\n",
        "LBSP = LaboSpace(960, 640)\n",
        "LBSP.load_receptor(PROT_view_pFile)\\\n",
        "    .set_style(\n",
        "        show_represent=Show_representation,\n",
        "        represent_type=Representation_type,\n",
        "        represent_style=builtin_style(\n",
        "            style=Representation_style,\n",
        "            opacity=Representation_opacity))\\\n",
        "    .add_residues(\n",
        "        show_residues=Show_residue,\n",
        "        residue_number=Residue_number)\\\n",
        "    .add_surface(\n",
        "        show_surface=Show_surface,\n",
        "        surface_type=Surface_type,\n",
        "        surface_style=builtin_style(\n",
        "            style=Surface_style,\n",
        "            opacity=Surface_opacity))\n",
        "LBSP.view_space()\n",
        "\n",
        "show_cscale(\n",
        "    {Show_representation: Representation_style},\n",
        "    {Show_surface: Surface_style})"
      ],
      "metadata": {
        "cellView": "form",
        "id": "W1CdbmU8GFTD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "EX4JXArPCcXO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title **Parameterise protein with Gasteiger charges**\n",
        "# @markdown Enter the **< Target Protein >** to be parameterised.\\\n",
        "# @markdown This generate a **`protein.pdbqt`** file after:\n",
        "# @markdown + Addition of Gasteiger Partial Charge\n",
        "# @markdown + Addition of polar hydrogens\n",
        "# @markdown + Removal of non-polar hydrogens\n",
        "\n",
        "Target_protein = '7N3N_prot_A' # @param {type:'string'}\n",
        "\n",
        "PROT_pdb = Target_protein + '.pdb'\n",
        "PROT_pdbqt = Target_protein + '.pdbqt'\n",
        "PROT_pdb_pFile = os.path.join(PRT_FLD, PROT_pdb)\n",
        "PROT_pdb_dFile = os.path.join(DCK_FLD, PROT_pdb)\n",
        "PROT_pdbqt_dFile = os.path.join(DCK_FLD, PROT_pdbqt)\n",
        "\n",
        "!obabel {PROT_pdb_pFile} -xr -O {PROT_pdbqt_dFile} -h --partialcharge gasteiger > /dev/null 2>&1\n",
        "!mk_prepare_receptor.py --pdbqt {PROT_pdbqt_dFile} -o {PROT_pdbqt_dFile} --skip_gpf > /dev/null 2>&1\n",
        "print(f'+ Parameterisation: {PROT_pdb} > {PROT_pdbqt}')\n",
        "\n",
        "shutil.copy(PROT_pdb_pFile, PROT_pdb_dFile)\n",
        "print(f'+ {PROT_pdbqt} > DOCKING folder')\n",
        "print(f'+ {PROT_pdb} > DOCKING folder')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "g5OEiuwwGJi4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "---\n",
        " **03 | Preparing the Native Ligand** (optional)\n",
        "\n",
        "Next, we retrieve the native ligand from the **`pdb`** file to serve as a reference for later comparison. Noted that **this step is optional** as not all **`pdb`** files contain native ligand. However, we highly recommend proceeding with this step for an insightful visual (3D inspection) and qualtitative (RMSD) comparison of binding pose."
      ],
      "metadata": {
        "id": "MncWQZLPGOAx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title **Retrieve native ligand and extract subunits**\n",
        "# @markdown Enter the **< Keyword >** assigned for query \\\n",
        "# @markdown This generates a **clean** native ligand structure containing multiple\n",
        "# @markdown binding poses corresponding to each protein subunit(s). \\\n",
        "# @markdown The binding poses are then extracted and corrected into individual\n",
        "# @markdown **`pdb`** files.\n",
        "\n",
        "Keyword = 'FUN' # @param {type: 'string'}\n",
        "\n",
        "def extract_ligand(inpt_file: str, oupt_file: str, keyword: str) -> None:\n",
        "    oupt_name, oupt_dirn, oupt_path = oupt_parse(oupt_file)\n",
        "    with open(inpt_file, 'r') as inpt, \\\n",
        "         open(oupt_file, 'w') as oupt:\n",
        "        for line in inpt:\n",
        "            record = line.split()[0]\n",
        "            lig_id = line[16:20].strip()\n",
        "            if 'HETATM' in record and keyword in lig_id:\n",
        "                assert len(lig_id) <= 3 or lig_id == keyword, f'Try keyword \\'{lig_id}\\''\n",
        "                oupt.write(line)\n",
        "    print(f'+ Ligand extracted: {oupt_name}.pdb > {oupt_dirn} folder')\n",
        "\n",
        "def get_molblock(keyword: str) -> str:\n",
        "    url_path = 'http://files.rcsb.org/ligands/download/' + keyword + '_model.sdf'\n",
        "    sdf_file = os.path.join(NTV_FLD, keyword + '.sdf')\n",
        "    os.system(f'wget {url_path} -O {sdf_file} -q')\n",
        "    molblock = [mol for mol in  Chem.SDMolSupplier(sdf_file) if mol is not None][0]\n",
        "    os.remove(sdf_file)\n",
        "    return molblock\n",
        "\n",
        "def correct_bond_order(inpt_list: list, temp: Chem.rdchem.Mol) -> None:\n",
        "    for inpt_file in inpt_list:\n",
        "        targ = AllChem.MolFromPDBFile(inpt_file)\n",
        "        cmol = AllChem.AssignBondOrdersFromTemplate(temp, targ)\n",
        "        pdbb = Chem.MolToPDBBlock(cmol, flavor=4)\n",
        "        with open(inpt_file, 'w') as oupt:\n",
        "            oupt.write(pdbb)\n",
        "\n",
        "true_keyword = Keyword[-3:] if len(Keyword) > 3 else Keyword\n",
        "print(f'+ RCSB PDB link: https://www.rcsb.org/ligand/{true_keyword}')\n",
        "\n",
        "ntv_pdb = Keyword.upper() + '.pdb'\n",
        "ntv_pdb_nFile = os.path.join(NTV_FLD, ntv_pdb)\n",
        "extract_ligand(PDB_pdb_pFile, ntv_pdb_nFile, Keyword)\n",
        "extract_chains(ntv_pdb_nFile)\n",
        "\n",
        "ntv_nFiles = sorted(glob.glob(NTV_FLD + '/' + Keyword + '_*.pdb'))\n",
        "ntv_smiles = get_molblock(true_keyword)\n",
        "correct_bond_order(ntv_nFiles, ntv_smiles)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "utmBeWeHGQV9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title **Visualise 3D native ligand**\n",
        "# @markdown Enter the **< Native Ligand >** to be viewed.\n",
        "\n",
        "View = 'FUN_A' # @param {type:'string'}\n",
        "Representation_type = 'stick' # @param ['line', 'sphere', 'stick']\n",
        "Show_atom_labels = False # @param {type:'boolean'}\n",
        "\n",
        "NTV_view_nFile = os.path.join(NTV_FLD, View + '.pdb')\n",
        "\n",
        "LBSP = LaboSpace(960, 640)\n",
        "LBSP.load_ligand(NTV_view_nFile)\\\n",
        "    .set_style(\n",
        "        show_represent=True,\n",
        "        represent_type=Representation_type,\n",
        "        represent_style={'colorscheme': 'lightGreyCarbon'})\\\n",
        "    .label_atoms(\n",
        "        show_label=Show_atom_labels)\n",
        "LBSP.view_space()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "YAWuhhrwGV8v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title **Select native ligand**\n",
        "# @markdown Enter the **< Target Native Ligand >** for later comparison.\n",
        "\n",
        "Target_native_ligand = 'FUN_A' # @param {type:'string'}\n",
        "\n",
        "NTV_pdb = Target_native_ligand + '.pdb'\n",
        "NTV_pdb_nFile = os.path.join(NTV_FLD, NTV_pdb)\n",
        "NTV_pdb_dFile = os.path.join(DCK_FLD, NTV_pdb)\n",
        "\n",
        "shutil.copy(NTV_pdb_nFile, NTV_pdb_dFile)\n",
        "print(f'+ {NTV_pdb} > DOCKING folder')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "LHq0RRltGapQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "---\n",
        " **04 | Preparing the Ligand**\n",
        "\n",
        "Now, we start to prepare our ligands of interest by uploading the compound library in **`csv`** format onto the **`LIGAND`** folder. We will be using their SMILES notations (canonical/Isomeric) to generate the 3D energetically minimised ligand **`sd`** files based on specifed force field and conjugate gradient algorithm. We also parameterise our ligands to generate the **`pdbqt`** file required for virtual screening."
      ],
      "metadata": {
        "id": "0wE9KNM7Gimv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title **Provide compound library**\n",
        "# @markdown Upload a **< Compound Library >**  onto LIGAND folder.\\\n",
        "# @markdown The file **must** contain the below information with headers:\n",
        "# @markdown + **`ID`** : The identity assigned to ligand\n",
        "# @markdown + **`SMILES`** : The SMILES notation\n",
        "\n",
        "Compoud_library = 'LIB' # @param {type:\"string\"}\n",
        "\n",
        "CMPLIB_csv = Compoud_library + '.csv'\n",
        "CMPLIB_csv_lFile = os.path.join(LIG_FLD, CMPLIB_csv)\n",
        "CMPLIB_df = pd.read_csv(CMPLIB_csv_lFile)[['ID', 'SMILES']]\n",
        "CMPLIB_df"
      ],
      "metadata": {
        "cellView": "form",
        "id": "xVDf3IcIGgOp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title **Generate ligand SD files**\n",
        "# @markdown Select **< Gradient >** to set energy minimisation approach. **[ Default is conjugate ]** \\\n",
        "# @markdown Select **< Force Field >** to set MM method for energy minimisation. **[ Default is UFF ]** \\\n",
        "# @markdown Select **< Convergence Criteria >** to set minimum iteration difference required before stopping. **[ Default is 0.001 ]** \\\n",
        "# @markdown Select **< Maximum Steps >** to set maximum iterations allowed for minimisation. **[ Default is 10000 ]**\n",
        "\n",
        "Gradient = 'conjugate' # @param ['steepest', 'conjugate']\n",
        "Force_field = 'UFF' # @param ['GAFF', 'Ghemical', 'MMFF94', 'MMFF94s', 'UFF']\n",
        "Convergence_criteria = '0.00001' # @param ['0.1', '0.01', '0.001', '0.0001', '0.00001', '0.000001', '0.0000001']\n",
        "Maximum_steps = 10000 # @param {type: 'slider', min:1000, max:100000, step:1000}\n",
        "\n",
        "def check_convergence(log_file: str) -> None:\n",
        "    with open(log_file, 'r') as inpt:\n",
        "        data = inpt.read()\n",
        "\n",
        "    mol_data = [line.strip().split('\\n') for line in data.split('#######')][:-1]\n",
        "    uncon_id = [line[0][8:] for line in mol_data[1:] if 'CONVERGED' not in line[-2]]\n",
        "    gradient = mol_data[0][0][10:]\n",
        "    num_convg = len(mol_data[1:]) - len(uncon_id)\n",
        "    uncon_str = 'EXCEPT ' + ', '.join(uncon_id) if uncon_id else ''\n",
        "\n",
        "    print(f'+ Total {num_convg} ligand has achieved convergence with '\n",
        "          f'{gradient} gradient {uncon_str}')\n",
        "\n",
        "CMPLIB_obmin_log = Compoud_library + '_obmin.log'\n",
        "CMPLIB_obmin_log_lfile = os.path.join(LIG_FLD, CMPLIB_obmin_log)\n",
        "os.remove(CMPLIB_obmin_log_lfile) if os.path.exists(CMPLIB_obmin_log_lfile) else None\n",
        "\n",
        "# Append 'GRADIENT' used for energy minimisation onto obmin.log\n",
        "with open(CMPLIB_obmin_log_lfile, 'a') as log:\n",
        "    log.write(f'GRADIENT: {Gradient}\\n')\n",
        "\n",
        "count = 0\n",
        "statement = True\n",
        "for LIG_ID, LIG_SMI in zip(tqdm(CMPLIB_df['ID']), CMPLIB_df['SMILES']):\n",
        "\n",
        "    if statement:\n",
        "        print(f'+ Selected {Force_field} '\n",
        "              f'with {Gradient} gradient for energy minimisation '\n",
        "              f'up to {Convergence_criteria} iteration difference or '\n",
        "              f'at most {Maximum_steps:,} steps')\n",
        "    statement = False\n",
        "\n",
        "    LIG_sdf = LIG_ID + '.sdf'\n",
        "    LIG_obmin_log = LIG_ID + '_obmin.log'\n",
        "    LIG_sdf_lFile = os.path.join(LIG_FLD, LIG_sdf)\n",
        "\n",
        "    # Append 'LIGAND ID' and 'DELIMITER' onto obmin.log\n",
        "    with open(CMPLIB_obmin_log_lfile, 'a') as log:\n",
        "        log.write(f'#######\\n')\n",
        "        log.write(f'LIGAND: {LIG_ID}\\n')\n",
        "\n",
        "    !obabel -:{'\"'+LIG_SMI+'\"'} -O {LIG_sdf_lFile} --title {LIG_ID} --gen3d \\\n",
        "    --best --minimize --ff {Force_field} --steps {Maximum_steps} \\\n",
        "    --crit {Convergence_criteria} --log &>> {CMPLIB_obmin_log_lfile}\n",
        "\n",
        "    count += 1\n",
        "\n",
        "# Append last 'DELIMITER' onto obmin.log\n",
        "with open(CMPLIB_obmin_log_lfile, 'a') as log:\n",
        "    log.write(f'#######')\n",
        "\n",
        "check_convergence(CMPLIB_obmin_log_lfile)\n",
        "print(f'+ {count} ligand.sdf > LIGAND folder')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "daugQWzVGprl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title **Visualise 3D ligand**\n",
        "# @markdown Enter the **< Ligand >** to be viewed.\n",
        "\n",
        "View = 'R002' # @param {type:'string'}\n",
        "Representation_type = 'stick' # @param ['line', 'sphere', 'stick']\n",
        "Show_atom_labels = False # @param {type:'boolean'}\n",
        "\n",
        "LIG_view_lFile = os.path.join(LIG_FLD, View + '.sdf')\n",
        "\n",
        "LBSP = LaboSpace(960, 640)\n",
        "LBSP.load_ligand(LIG_view_lFile)\\\n",
        "    .set_style(\n",
        "        show_represent=True,\n",
        "        represent_type=Representation_type,\n",
        "        represent_style={'colorScheme': 'lightGreyCarbon'})\\\n",
        "    .label_atoms(\n",
        "        show_label=Show_atom_labels)\n",
        "LBSP.view_space()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "_E3UKPlfGuEc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title **Parameterise ligands with Gasteiger charges**\n",
        "# @markdown This generate **`ligand.pdbqt`** files after:\n",
        "# @markdown + Addition of Gasteiger Partial Charge\n",
        "# @markdown + Removal of non-polar hydrogens\n",
        "\n",
        "def pdbqt_add_chid(inpt_file: str) -> None:\n",
        "    with open(inpt_file, 'r') as inpt:\n",
        "        data = inpt.read()\n",
        "    new_data = data.replace('  UNL  ', '  UNL A')\n",
        "    with open(inpt_file, 'w') as oupt:\n",
        "        oupt.write(new_data)\n",
        "\n",
        "count = 0\n",
        "for LIG_ID in tqdm(CMPLIB_df['ID']):\n",
        "    LIG_sdf = LIG_ID + '.sdf'\n",
        "    LIG_pdbqt = LIG_ID + '.pdbqt'\n",
        "    LIG_dFLD = os.path.join(DCK_FLD, LIG_ID)\n",
        "    LIG_sdf_lFile = os.path.join(LIG_FLD, LIG_sdf)\n",
        "    LIG_pdbqt_dFFile = os.path.join(LIG_dFLD, LIG_pdbqt)\n",
        "\n",
        "    try:\n",
        "        os.makedirs(LIG_dFLD, exist_ok=True)\n",
        "        !mk_prepare_ligand.py -i {LIG_sdf_lFile} -o {LIG_pdbqt_dFFile} > /dev/null 2>&1\n",
        "        pdbqt_add_chid(LIG_pdbqt_dFFile)\n",
        "        count += 1\n",
        "    except:\n",
        "        print(f'+ Error in preparing {LIG_ID}')\n",
        "        os.rmdir(LIG_dFLD)\n",
        "        continue\n",
        "\n",
        "print(f'+ Parameterisation: {count} ligand.sdf > {count} ligand.pdbqt')\n",
        "print(f'+ {count} ligand.pdbqt files > DOCKING folder')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Dw7HaG3IGxPu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "---\n",
        " **05 | Setting Up Grid Box**\n",
        "\n",
        "Here, we define a chemical search space with the use of grid box, which often centered within the binding, active or allosteric site of the target protein."
      ],
      "metadata": {
        "id": "BVTXsWjqG4kI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Built-in methods for defining grid box include:\n",
        "\n",
        "+ **`LaBOX`** : Use the mean of XYZ extreme values from native ligand. [Link](https://github.com/RyanZR/LaBOX)\n",
        "+ **`eBoxSize`** : Use the radius of gyration of native ligand. [Link](https://github.com/michal-brylinski/eboxsize)\n",
        "+ **`eBoxSize-Mod`** : Similar to eBoxSize, but box center is computed using LaBOX method.\n",
        "+ **`Autodock-Grid`** : 22.5 × 22.5 × 22.5 Å\n",
        "+ **`Defined-by-Res`** : Use when important residues involved in binding interaction are known.\n",
        "+ **`Blind-Docking`** : Use when binding pocket is not known.\n",
        "+ **`Manual-Mode`** : Use the sliders below to define grid box."
      ],
      "metadata": {
        "id": "phG32r4-G-8t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title **Place grid box at binding site**\n",
        "# @markdown Select **< Method >** to set grid box at the center of binding site.\n",
        "\n",
        "Residue_number = '' # @param {type: 'string'}\n",
        "Method = 'LaBOX' # @param ['LaBOX', 'eBoxSize', 'eBoxSize-Mod', 'Autodock-Grid', 'Defined-by-Res', 'Manual-Mode']\n",
        "Show_residues = True # @param {type: 'boolean'}\n",
        "\n",
        "# @markdown **Manual Mode**\n",
        "\n",
        "X = 0 # @param {type: 'number'}\n",
        "Y = 0 # @param {type: 'number'}\n",
        "Z = 0 # @param {type: 'number'}\n",
        "Width = 10 # @param {type: 'number'}\n",
        "Height = 10 # @param {type: 'number'}\n",
        "Depth = 10 # @param {type: 'number'}\n",
        "Scale = 1.0 # @param {type: 'number'}\n",
        "\n",
        "LBSP = LaboSpace(960, 640)\n",
        "LBSP_view = True\n",
        "\n",
        "try:\n",
        "    if Method == 'Defined-by-Res':\n",
        "        GB = GridBox(PROT_pdb_dFile)\n",
        "        center, bxsize = GB.defined_by_res(Residue_number)\n",
        "    if Method == 'Manual-Mode':\n",
        "        center = (X, Y, Z)\n",
        "        bxsize = (round(Width, 3),\n",
        "                  round(Height, 3),\n",
        "                  round(Depth, 3))\n",
        "except Exception as excp:\n",
        "    print(f'+ {excp}')\n",
        "    print(f'+ Error can be:\\n'\n",
        "            + '  - Expected \\'Residue_number\\'; found nothing\\n'\n",
        "            + '  - Expected \\'protein PDB file\\'; found nothing\\n'\n",
        "            + '  - Due to atomic error in \\'protein PDB file\\'')\n",
        "    LBSP_view = False\n",
        "else:\n",
        "    LBSP.load_receptor(PROT_pdb_dFile)\\\n",
        "        .set_style(\n",
        "            show_represent=True,\n",
        "            represent_type='cartoon',\n",
        "            represent_style={'color': 'white'})\\\n",
        "        .add_residues(\n",
        "            show_residues=Show_residues,\n",
        "            residue_number=Residue_number)\n",
        "\n",
        "try:\n",
        "    if Method == 'LaBOX':\n",
        "        GB = GridBox(NTV_pdb_nFile)\n",
        "        center, bxsize = GB.labox()\n",
        "    if Method == 'eBoxSize':\n",
        "        GB = GridBox(NTV_pdb_nFile)\n",
        "        center, bxsize = GB.eboxsize()\n",
        "    if Method == 'eBoxSize-Mod':\n",
        "        GB = GridBox(NTV_pdb_nFile)\n",
        "        center, bxsize = GB.eboxsize(modified=True)\n",
        "    if Method == 'Autodock-Grid':\n",
        "        GB = GridBox(NTV_pdb_nFile)\n",
        "        center, bxsize = GB.autodock_grid()\n",
        "except Exception as excp:\n",
        "    print(f'+ {excp}')\n",
        "    print(f'+ Expected \\'native ligand PDB file\\'; found nothing')\n",
        "    print(f'+ Upload file to \\'{NTV_FLD}\\' and run \\'Select native ligand\\' cell to load it.')\n",
        "    LBSP_view = False\n",
        "else:\n",
        "    try:\n",
        "        LBSP.load_ligand(NTV_pdb_nFile)\\\n",
        "            .set_style(\n",
        "                show_represent=True,\n",
        "                represent_type='stick',\n",
        "                represent_style={'colorScheme': 'greyCarbon'})\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "if LBSP_view:\n",
        "    LBSP.add_gridbox(show_gridbox=True, center=center, bxsize=bxsize)\n",
        "    LBSP.view_space()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "sMoYvcIRG-oP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title **Generate docking config file**\n",
        "# @markdown This generates **`config_file`** for AutoDock Vina.\n",
        "\n",
        "cfg_name = 'config_file'\n",
        "cfg_dFile = os.path.join(DCK_FLD, cfg_name)\n",
        "\n",
        "with open(cfg_dFile, 'w') as cfg:\n",
        "    cfg.write(f'center_x = {center[0]}\\n')\n",
        "    cfg.write(f'center_y = {center[1]}\\n')\n",
        "    cfg.write(f'center_z = {center[2]}\\n')\n",
        "    cfg.write(f'\\n')\n",
        "    cfg.write(f'size_x = {bxsize[0]}\\n')\n",
        "    cfg.write(f'size_y = {bxsize[1]}\\n')\n",
        "    cfg.write(f'size_z = {bxsize[2]}\\n')\n",
        "\n",
        "print(f'+ {cfg_name} > DOCKING folder')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "V3ZQGbltHGRE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "---\n",
        " **06 | Performing Virtual Screening**\n",
        "\n",
        "We now proceed with virtual screening using Autodock Vina for our target ligands in the compound library. The duration can vary, mainly influenced by factors including **number of ligands**, **number of rotatable bonds** and **level of exhaustiveness** selected. Do be patient as the process may take a few hours to complete."
      ],
      "metadata": {
        "id": "-ykcsBqlHOnP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title **Run AutoDock Vina**\n",
        "# @markdown Select **< Scoring >**  to set scoring option. **[ Default is vina ]** \\\n",
        "# @markdown Select **< Exhaustiveness >** to change the computational effort. **[ Default is 16 ]** \\\n",
        "# @markdown This generates a **`output.pdbqt`** containing different binding\n",
        "# @markdown poses predicted for each docked ligand.\n",
        "\n",
        "Scoring = 'vina' # @param ['vina', 'vinardo']\n",
        "Exhaustiveness = '16' # @param [4, 8, 16, 32, 64, 128, 256]\n",
        "\n",
        "cpu_cores = os.cpu_count()\n",
        "LIG_dFLDs = sorted(folder[:-1] for folder in glob.glob(DCK_FLD + '/*/'))\n",
        "\n",
        "# -- Start screening --\n",
        "start = time.time()\n",
        "count = 0\n",
        "for folder in tqdm(LIG_dFLDs):\n",
        "    LIG_ID = os.path.basename(folder)\n",
        "    LIG_pdbqt = LIG_ID + '.pdbqt'\n",
        "    LIG_oupt_log = LIG_ID + '_output.log'\n",
        "    LIG_oupt_pdbqt = LIG_ID + '_output.pdbqt'\n",
        "    LIG_dFLD = os.path.join(DCK_FLD, LIG_ID)\n",
        "    LIG_pdbqt_dFFile = os.path.join(LIG_dFLD, LIG_pdbqt)\n",
        "    LIG_oupt_log_dFFile = os.path.join(LIG_dFLD, LIG_oupt_log)\n",
        "    LIG_oupt_pdbqt_dFFile = os.path.join(LIG_dFLD, LIG_oupt_pdbqt)\n",
        "\n",
        "    %vina --receptor {PROT_pdbqt_dFile} --ligand {LIG_pdbqt_dFFile} \\\n",
        "    --out {LIG_oupt_pdbqt_dFFile} --config {cfg_dFile} --scoring {Scoring} \\\n",
        "    --exhaustiveness {Exhaustiveness} --cpu {cpu_cores} \\\n",
        "    --verbosity 2 &> {LIG_oupt_log_dFFile}\n",
        "\n",
        "    count += 1\n",
        "end = time.time()\n",
        "# -- End screening --\n",
        "\n",
        "print(f'')\n",
        "print(f'+ Screening completed')\n",
        "print(f'+ Time elapsed: ' + time.strftime('%Mm %Ss', time.gmtime(end - start)))\n",
        "print(f'+ {count} ligand_output.pdbqt > DOCKING folder')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "IyeLIoY3HRA_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title **Process output file**\n",
        "# @markdown This generates **`ligand_[n].pdb`** for the binding poses of\n",
        "# @markdown each docked ligand.\n",
        "\n",
        "count = 0\n",
        "for folder in tqdm(LIG_dFLDs):\n",
        "    LIG_ID = os.path.basename(folder)\n",
        "    LID_dash_pdb = LIG_ID + '_.pdb'\n",
        "    LIG_oupt_pdbqt = LIG_ID + '_output.pdbqt'\n",
        "    LIG_dash_pdb_dFFile = os.path.join(folder, LID_dash_pdb)\n",
        "    LIG_oupt_pdbqt_dFFile = os.path.join(folder, LIG_oupt_pdbqt)\n",
        "\n",
        "    with open(LIG_oupt_pdbqt_dFFile, 'r') as oupt:\n",
        "        data = oupt.read()\n",
        "        pose = data.count('MODEL')\n",
        "        count += pose\n",
        "\n",
        "    !obabel {LIG_oupt_pdbqt_dFFile} -O {LIG_dash_pdb_dFFile} -m > /dev/null 2>&1\n",
        "\n",
        "print(f'+ Total {count} ligand_[n].pdb > DOCKING folder')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "GVCkXIaSHW-E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "---\n",
        " **07 | Profiling Binding Interactions**\n",
        "\n",
        "After docking, we use PLIP to determine the non-covalent binding interactions between the docked ligands and target protein. We will prepare the required complex **`pdb`** file containing docked ligand pose and target protein for PLIP to profile interactions."
      ],
      "metadata": {
        "id": "_sZ7IZWRHbr-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title **Generate complex PDB file**\n",
        "# @markdown This merges the target protein with the binding poses of each docked\n",
        "# @markdown ligand to produce individual **`cmpx.pdb`** file.\n",
        "\n",
        "def generate_cmpx_pdb(inpt_prot: str, inpt_pose: str, oupt_cmpx: str) -> None:\n",
        "\n",
        "    def write_line(line: str, keywords: list, oupt_file: str) -> None:\n",
        "        header = line.split()[0]\n",
        "        if header in keywords:\n",
        "            oupt_file.write(line)\n",
        "\n",
        "    def cmpx_writer() -> None:\n",
        "        with open(oupt_cmpx, 'w') as oupt_file, \\\n",
        "             open(inpt_prot, 'r') as prot_file, \\\n",
        "             open(inpt_pose, 'r') as pose_file:\n",
        "            for prot_line in prot_file:\n",
        "                write_line(prot_line, prot_headers, oupt_file)\n",
        "            for pose_line in pose_file:\n",
        "                write_line(pose_line, pose_headers, oupt_file)\n",
        "\n",
        "    prot_headers = ['ATOM', 'CONECT', 'TER']\n",
        "    pose_headers = ['ATOM', 'CONECT', 'END']\n",
        "    cmpx_writer()\n",
        "\n",
        "count = 0\n",
        "for folder in tqdm(LIG_dFLDs):\n",
        "    LIG_ID = os.path.basename(folder)\n",
        "    LIG_iFLD = os.path.join(INT_FLD, LIG_ID)\n",
        "    os.makedirs(LIG_iFLD, exist_ok=True)\n",
        "\n",
        "    LIG_pdb_dFFiles = sorted(glob.glob(folder + '/*.pdb'))\n",
        "    for pose_file in LIG_pdb_dFFiles:\n",
        "        pose_name = os.path.basename(pose_file).split('.')[0]\n",
        "        cmpx_pdb = pose_name + '_cmpx.pdb'\n",
        "        cmpx_pdb_ifile = os.path.join(LIG_iFLD, cmpx_pdb)\n",
        "        generate_cmpx_pdb(PROT_pdb_dFile, pose_file, cmpx_pdb_ifile)\n",
        "        count += 1\n",
        "\n",
        "print(f'+ {count} ligand_[n]_cmpx.pdb > INTERACTION folder')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "12OtdkS6HdPI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title **Run PLIP**\n",
        "# @markdown This generates an **`interpt.csv`** containing all detected binding\n",
        "# @markdown interactions for each individual **`cmpx.pdb`** file. \\\n",
        "# @markdown Supported: **`HYDROPHOBIC`**, **`HBOND`**, **`WATERBRIDGE`**,\n",
        "# @markdown **`SALTBRIDGE`**, **`PISTACKING`**, **`PICATION`**, **`HALOGEN`**, **`METAL`**. \\\n",
        "\n",
        "def interaction_profiler(inpt_cmpx: str, oupt_csv: str) -> None:\n",
        "\n",
        "    int_bonds = ['HYDROPHOBIC', 'HBOND', 'WATERBRIDGE', 'SALTBRIDGE',\n",
        "                 'PISTACKING', 'PICATION', 'HALOGEN', 'METAL']\n",
        "\n",
        "    def BSR(inpt_cmpx: str) -> object:\n",
        "        cmpx_mol = PDBComplex()\n",
        "        cmpx_mol.load_pdb(inpt_cmpx)\n",
        "        cmpx_lig = [lig for lig in cmpx_mol.ligands if lig.hetid == 'UNL'][0]\n",
        "        cmpx_mol.characterize_complex(cmpx_lig)\n",
        "        cmpx_int = cmpx_mol.interaction_sets['UNL:A:1']\n",
        "        cmpx_rpt = BindingSiteReport(cmpx_int)\n",
        "        return cmpx_rpt\n",
        "\n",
        "    def BSR_feat(bsr: object) -> list:\n",
        "        return [list(getattr(bsr, bond.lower() + '_features')) + ['BOND']\n",
        "                for bond in int_bonds]\n",
        "\n",
        "    def BSR_info(bsr: object) -> list:\n",
        "        return [[list(info) + [bond] for info in getattr(bsr, bond.lower() + '_info')]\n",
        "                for bond in int_bonds]\n",
        "\n",
        "    def replace_column(df: pd.DataFrame, col_A: str, cols: list) -> pd.DataFrame:\n",
        "        for col in cols:\n",
        "            if col in df.columns:\n",
        "                df[col_A] = df[col_A].fillna(df[col])\n",
        "            else:\n",
        "                pass\n",
        "        return df\n",
        "\n",
        "    def BSR_dataframe(bsr_feat: list, bsr_info: list) -> pd.DataFrame:\n",
        "        bsr_df = []\n",
        "        for feat, info in zip(bsr_feat, bsr_info):\n",
        "            if info:\n",
        "                df = pd.DataFrame(info, columns=feat)\n",
        "            else:\n",
        "                df = pd.DataFrame(columns=bsr_feat[0])\n",
        "            bsr_df.append(df)\n",
        "        BSR_df = pd.concat(bsr_df, ignore_index=True)\n",
        "        BSR_df = replace_column(BSR_df, 'DIST', ['DIST_D-A', 'CENTDIST'])\n",
        "        return BSR_df\n",
        "\n",
        "    cmpx_bsr = BSR(inpt_cmpx)\n",
        "    bsr_feat = BSR_feat(cmpx_bsr)\n",
        "    bsr_info = BSR_info(cmpx_bsr)\n",
        "    bsr_data = BSR_dataframe(bsr_feat, bsr_info)\n",
        "    bsr_data.to_csv(oupt_csv, index=False)\n",
        "\n",
        "LIG_iFLDs = sorted(folder[:-1] for folder in glob.glob(INT_FLD + '/*/'))\n",
        "\n",
        "count = 0\n",
        "for folder in tqdm(LIG_iFLDs):\n",
        "    cmpx_pdb_iFFiles = sorted(glob.glob(folder + '/*_cmpx.pdb'))\n",
        "\n",
        "    for cmpx_file in cmpx_pdb_iFFiles:\n",
        "        cmpx_name = os.path.basename(cmpx_file).split('.')[0][:-5]\n",
        "        inter_csv = cmpx_name + '_interpt.csv'\n",
        "        inter_csv_iFile = os.path.join(folder, inter_csv)\n",
        "        interaction_profiler(cmpx_file, inter_csv_iFile)\n",
        "        count += 1\n",
        "\n",
        "print(f'+ {count} ligand_[n]_interpt.pdb > INTERACTION folder')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "QHLZuBtwHyPu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "---\n",
        " **08 | Analysing Screening Results**\n",
        "\n",
        "We process all the docking and binding internaction results generated into for further evaluation. We will compute the RMSD between native ligand and docked ligands based on maximum common substructure (MCS). We will also visualise the docking pose in three-dimensional chemical space."
      ],
      "metadata": {
        "id": "cgx4Ua4DH2om"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title **Cluster and generate docking reports**\n",
        "# @markdown Select **< Mode >** to specify clustering criteria.\\\n",
        "# @markdown This computes the LABO-RMSD and clusters docking results based on\n",
        "# @markdown user-specified mode.\\\n",
        "# @markdown This also ranks the binding interaction based on their occurences from\n",
        "# @markdown the clustered ligands. \\\n",
        "# @markdown Multiple **`report.csv`** file  will be generated including:\n",
        "# @markdown + **`[ligand]_dockrpt.csv`** : Individual docking result of each ligand pose\n",
        "# @markdown + **`[CMPLIB]_clusrpt.csv`** : Clustered docking results based on score and RMSD\n",
        "# @markdown + **`[CMPLIB]_interpt.csv`** : Binding interactions result with bonds ranked by frequency\n",
        "\n",
        "Mode = 'LABO-RMSD' # @param ['Best-Pose', 'LABO-RMSD']\n",
        "\n",
        "def vina_report(inpt_file: str) -> dict:\n",
        "\n",
        "    def vn_scores(inpt_file: str) -> float:\n",
        "        with open(inpt_file, 'r') as inpt:\n",
        "            for line in inpt:\n",
        "                if 'REMARK VINA RESULT' in line:\n",
        "                    dock_sc = float(line.split()[3])\n",
        "                    rmsd_lb = float(line.split()[4])\n",
        "                    rmsd_ub = float(line.split()[5])\n",
        "        return dock_sc, rmsd_lb, rmsd_ub\n",
        "\n",
        "    def vn_report(name: str, scores: tuple) -> dict:\n",
        "        return {'NAME': [name], 'DOCK_SC': [scores[0]],\n",
        "                'RMSD_LB': [scores[1]], 'RMSD_UB': [scores[2]]}\n",
        "\n",
        "    inpt_name = os.path.basename(inpt_file).split('.')[0]\n",
        "    scores = vn_scores(inpt_file)\n",
        "    report = vn_report(inpt_name, scores)\n",
        "    return report\n",
        "\n",
        "def clustering(mode: str, rpt_df: pd.DataFrame) -> pd.DataFrame:\n",
        "\n",
        "    def best_pose(df: pd.DataFrame) -> pd.DataFrame:\n",
        "        df = df[rpt_df['NAME'].str.endswith('_1')]\n",
        "        df = df.sort_values(['DOCK_SC'])\n",
        "        return df\n",
        "\n",
        "    def labo_rmsd(df: pd.DataFrame) -> pd.DataFrame:\n",
        "        df.insert(0, 'LIG', df['NAME'].str[:-2])\n",
        "        df = df.sort_values(['LIG', 'LABO_RMSD']).groupby(['LIG']).first()\n",
        "        df = df.sort_values(['LABO_RMSD'])\n",
        "        return df\n",
        "\n",
        "    rpt_df = best_pose(rpt_df) if mode == 'Best-Pose' else labo_rmsd(rpt_df)\n",
        "    rpt_df = rpt_df.drop(['RMSD_LB', 'RMSD_UB'], axis=1)\n",
        "    rpt_df = rpt_df.reset_index(drop=True)\n",
        "    return rpt_df\n",
        "\n",
        "# Generate docking report for all ligand pose and MCS image\n",
        "count = 0\n",
        "for folder in tqdm(LIG_dFLDs):\n",
        "    LIG_ID = os.path.basename(folder)\n",
        "    LIG_MCS_png = LIG_ID + '_MCS.png'\n",
        "    LIG_dockrpt_csv = LIG_ID + '_dockrpt.csv'\n",
        "    LIG_MCS_png_dFFile = os.path.join(folder, LIG_MCS_png)\n",
        "    LIG_dockrpt_csv_dFFile = os.path.join(folder, LIG_dockrpt_csv)\n",
        "    LIG_pdb_dFFiles = sorted(glob.glob(folder + '/*.pdb'))\n",
        "\n",
        "    RMSD = ComputeRMSD()\n",
        "    dock_rpt = pd.DataFrame()\n",
        "\n",
        "    try:\n",
        "        ref_info = RMSD.load_molecule(NTV_pdb_dFile)\n",
        "\n",
        "    except:\n",
        "        print('+ Expected \\'native ligand PDB file\\' for RMSD calculation; found nothing.')\n",
        "        print('+ Docking report generation proceeded without RMSD calculation.')\n",
        "        for lig_file in LIG_pdb_dFFiles:\n",
        "            vina_rpt = pd.DataFrame.from_dict(vina_report(lig_file))\n",
        "            dock_rpt = pd.concat([dock_rpt, vina_rpt], ignore_index=True)\n",
        "\n",
        "    else:\n",
        "        for lig_file in LIG_pdb_dFFiles:\n",
        "            lig_info = RMSD.load_molecule(lig_file)\n",
        "            vina_rpt = pd.DataFrame.from_dict(vina_report(lig_file))\n",
        "            rmsd_rpt = pd.DataFrame.from_dict(\n",
        "                RMSD.rmsd_report(ref_info, lig_info, True, False, False)\n",
        "                ).drop('NAME', axis=1)\n",
        "            pose_rpt = pd.concat([vina_rpt, rmsd_rpt], axis=1)\n",
        "            dock_rpt = pd.concat([dock_rpt, pose_rpt], ignore_index=True)\n",
        "        RMSD.MCS_png.save(LIG_MCS_png_dFFile)\n",
        "\n",
        "    finally:\n",
        "        dock_rpt.to_csv(LIG_dockrpt_csv_dFFile, index=False)\n",
        "        count += 1\n",
        "\n",
        "print(f'+ {count} ligand_dockrpt.csv > DOCKING folder')\n",
        "\n",
        "# Generate an overall docking report\n",
        "CMPLIB_clusrpt_csv = Compoud_library + '_clusrpt.csv'\n",
        "CMPLIB_clusrpt_csv_dFile = os.path.join(DCK_FLD, CMPLIB_clusrpt_csv)\n",
        "CMPLIB_clus_rpt = pd.DataFrame()\n",
        "\n",
        "for folder in tqdm(LIG_dFLDs):\n",
        "    LIG_ID = os.path.basename(folder)\n",
        "    LIG_dockrpt_csv = LIG_ID + '_dockrpt.csv'\n",
        "    LIG_dockrpt_csv_dFFile = os.path.join(folder, LIG_dockrpt_csv)\n",
        "\n",
        "    LIG_dock_rpt = pd.read_csv(LIG_dockrpt_csv_dFFile)\n",
        "    CMPLIB_clus_rpt = pd.concat([CMPLIB_clus_rpt, LIG_dock_rpt], ignore_index=True)\n",
        "\n",
        "CMPLIB_clus_rpt = clustering(Mode, CMPLIB_clus_rpt)\n",
        "CMPLIB_clus_rpt.to_csv(CMPLIB_clusrpt_csv_dFile, index=False)\n",
        "\n",
        "print(f'+ {Compoud_library}_clusrpt.csv > DOCKING folder')\n",
        "\n",
        "# Generate a binding interaction report based on bond occurrences\n",
        "CMPLIB_interpt_csv = Compoud_library + '_interpt.csv'\n",
        "CMPLIB_interpt_csv_iFile = os.path.join(INT_FLD, CMPLIB_interpt_csv)\n",
        "CMPLIB_inter_rpt = pd.DataFrame()\n",
        "\n",
        "for CLIG_ID in tqdm(CMPLIB_clus_rpt['NAME']):\n",
        "    CLIG_inter_csv = CLIG_ID + '_interpt.csv'\n",
        "    folder = os.path.join(INT_FLD, CLIG_ID[:-2])\n",
        "    CLIG_inter_csv_iFFile = os.path.join(folder, CLIG_inter_csv)\n",
        "\n",
        "    CLIG_inter_rpt = pd.read_csv(CLIG_inter_csv_iFFile)\n",
        "    residue_column = CLIG_inter_rpt['RESTYPE'] + ' ' + CLIG_inter_rpt['RESNR'].astype(str)\n",
        "    CLIG_inter_rpt.insert(0, 'RESIDUE', residue_column)\n",
        "    inter_rpt = CLIG_inter_rpt[['RESIDUE', 'BOND']]\n",
        "    CMPLIB_inter_rpt = pd.concat([CMPLIB_inter_rpt, inter_rpt], ignore_index=True)\n",
        "\n",
        "CMPLIB_inter_rpt = CMPLIB_inter_rpt.groupby(['RESIDUE', 'BOND']).agg(FREQ=('BOND', 'count'))\n",
        "CMPLIB_inter_rpt = CMPLIB_inter_rpt.sort_values('FREQ')\n",
        "CMPLIB_inter_rpt = CMPLIB_inter_rpt.reset_index()\n",
        "CMPLIB_inter_rpt.to_csv(CMPLIB_interpt_csv_iFile, index=False)\n",
        "\n",
        "print(f'+ {Compoud_library}_interpt.csv > INTERACTION folder')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "JlC5AzYuH2WU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title **Rank docking result**\n",
        "# @markdown This ranks the docking results for each best pose based on specifed input.\n",
        "# @markdown + **`DOCK_SC`** : Autodock Vina Docking Score\n",
        "# @markdown + **`LABO_RMSD`** : RMSD by Common Substructure (vs Native Ligand)\n",
        "\n",
        "Sort_by = 'LABO_RMSD' # @param ['NAME', 'DOCK_SC', 'LABO_RMSD']\n",
        "Order = 'ascending' # @param ['ascending', 'descending']\n",
        "Top = 10 # @param {type: 'integer'}\n",
        "Maximum_RMSD = 2.5 # @param {type:\"number\"}\n",
        "\n",
        "order = {'ascending': True, 'descending': False}\n",
        "\n",
        "CMPLIB_clusrpt_df = pd.read_csv(CMPLIB_clusrpt_csv_dFile)\n",
        "CMPLIB_clusrpt_df = CMPLIB_clusrpt_df.sort_values([Sort_by], ascending=order[Order])\n",
        "CMPLIB_clusrpt_df = CMPLIB_clusrpt_df[:Top]\n",
        "CMPLIB_clusrpt_df = CMPLIB_clusrpt_df[CMPLIB_clusrpt_df['LABO_RMSD'] <= Maximum_RMSD]\n",
        "CMPLIB_clusrpt_df = CMPLIB_clusrpt_df.reset_index(drop=True)\n",
        "CMPLIB_clusrpt_df"
      ],
      "metadata": {
        "cellView": "form",
        "id": "tr0GQE1_IKnw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title **Show individual docking report**\n",
        "# @markdown Enter the **< Ligand Name >** to view docking score and RMSD.\n",
        "# @markdown + **`DOCK_SC`** : Autodock Vina Docking Score\n",
        "# @markdown + **`RMSD_LB`** : RMSD Lower Bound (vs Best Pose)\n",
        "# @markdown + **`RMSD_UB`** : RMSD Upper Bound (vs Best Pose)\n",
        "# @markdown + **`LABO_RMSD`** : RMSD by Common Substructure (vs Native Ligand)\n",
        "\n",
        "Ligand_name = 'R004' # @param {type : 'string'}\n",
        "\n",
        "LIG_dFLD = os.path.join(DCK_FLD, Ligand_name)\n",
        "LIG_dockrpt_csv = Ligand_name + '_dockrpt.csv'\n",
        "LIG_dockrpt_csv_dFile = os.path.join(LIG_dFLD, LIG_dockrpt_csv)\n",
        "LIG_dockrpt_df = pd.read_csv(LIG_dockrpt_csv_dFile)\n",
        "LIG_dockrpt_df"
      ],
      "metadata": {
        "cellView": "form",
        "id": "yAZfkj7LINp7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title **Rank binding interaction**\n",
        "# @markdown This ranks the binding interactions for each best pose based on specifed input.\n",
        "# @markdown + **`RESIDUE`** : Amino acids of protein\n",
        "# @markdown + **`BOND`** : Type of binding interactions\n",
        "# @markdown + **`FREQ`** : Frequency of occurrence\n",
        "\n",
        "Sort_by = 'FREQ' # @param ['RESIDUE', 'BOND', 'FREQ']\n",
        "Order = 'descending' # @param ['ascending', 'descending']\n",
        "Hide_hydrophobic = True # @param {type: 'boolean'}\n",
        "Show_barchart = True # @param {type: 'boolean'}\n",
        "\n",
        "order = {'ascending': True, 'descending': False}\n",
        "\n",
        "CMPLIB_interpt_df = pd.read_csv(CMPLIB_interpt_csv_iFile)\n",
        "CMPLIB_interpt_df = CMPLIB_interpt_df.sort_values([Sort_by], ascending=order[Order])\n",
        "CMPLIB_interpt_df = CMPLIB_interpt_df[\n",
        "    CMPLIB_interpt_df['BOND'] != 'HYDROPHOBIC'\n",
        "    ] if Hide_hydrophobic else CMPLIB_interpt_df\n",
        "CMPLIB_interpt_df = CMPLIB_interpt_df.reset_index(drop=True)\n",
        "display(CMPLIB_interpt_df)\n",
        "\n",
        "if Show_barchart:\n",
        "    width = len(CMPLIB_interpt_df) * 0.8\n",
        "    snsax = plt.subplots(figsize=(width, 5))[1]\n",
        "    bar_chart = sns.barplot(\n",
        "        data=CMPLIB_interpt_df,\n",
        "        x='RESIDUE',\n",
        "        y='FREQ',\n",
        "        hue='BOND',\n",
        "        ax=snsax)\n",
        "    bar_chart = plt.legend(title='BOND', loc='upper right')\n",
        "    bar_chart = plt.xlabel('RESIDUE', fontweight='bold')\n",
        "    bar_chart = plt.ylabel('FREQ', fontweight='bold')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "igXibB6zIO8w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title **Show individual interaction profile**\n",
        "# @markdown Enter the **< Pose Name >** to view the binding interactions.\n",
        "\n",
        "Pose_name = 'R004_8' # @param {type : 'string'}\n",
        "\n",
        "LIG_ID = Pose_name[:-2]\n",
        "LIG_iFLD = os.path.join(INT_FLD, LIG_ID)\n",
        "LIG_interpt_csv = Pose_name + '_interpt.csv'\n",
        "LIG_interpt_csv_iFile = os.path.join(LIG_iFLD, LIG_interpt_csv)\n",
        "LIG_interpt_dict = interaction_dict(LIG_interpt_csv_iFile, usage='view')\n",
        "LIG_interpt_df = pd.DataFrame.from_dict(LIG_interpt_dict)\n",
        "LIG_interpt_df = LIG_interpt_df[['RESTYPE', 'RESNR', 'DIST', 'BOND', 'COLOR']]\n",
        "LIG_interpt_df"
      ],
      "metadata": {
        "cellView": "form",
        "id": "GS1JN0bdIUc-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title **Visualise 3D docking pose**\n",
        "# @markdown **PROTEIN MODEL** \\\n",
        "# @markdown Enter the **< Protein >** to be viewed.\n",
        "\n",
        "View_protein = '7N3N_prot_A' # @param {type: 'string'}\n",
        "Protein_type = 'cartoon' # @param ['cartoon', 'cross', 'line', 'sphere', 'stick']\n",
        "Protein_style = 'white' # @param ['chain', 'white', 'whiteCarbon', 'ssJmol', 'ssPyMol', 'b factor', 'hydrophobicity', 'isoelectric points']\n",
        "Protein_opacity = 1 # @param {type: 'slider', min:0, max:1, step:0.1}\n",
        "Residue_number = '' # @param {type: 'string'}\n",
        "Surface_type = 'SES' # @param ['VDW', 'SAS', 'SES', 'MS']\n",
        "Surface_style = 'isoelectric points' # @param ['chain', 'white', 'whiteCarbon', 'ssJmol', 'ssPyMol', 'b factor', 'hydrophobicity', 'isoelectric points']\n",
        "Surface_opacity = 1 # @param {type: 'slider', min:0, max:1, step:0.1}\n",
        "Show_protein = False # @param {type: 'boolean'}\n",
        "Show_residue = False # @param {type: 'boolean'}\n",
        "Show_surface = True # @param {type: 'boolean'}\n",
        "Show_gridbox = False # @param {type: 'boolean'}\n",
        "\n",
        "# @markdown **LIGAND MODEL** \\\n",
        "# @markdown Enter the **< Ligand >** to be viewed.\n",
        "\n",
        "View_native_ligand = 'FUN_A' # @param {type: 'string'}\n",
        "Native_ligand_style = 'stick' # @param ['cross', 'line', 'sphere', 'stick']\n",
        "Show_native_ligand = True # @param {type: 'boolean'}\n",
        "View_docked_ligand = 'R004_5' # @param {type: 'string'}\n",
        "Docked_ligand_style = 'stick' # @param ['cross', 'line', 'sphere', 'stick']\n",
        "Show_docked_ligand = True # @param {type: 'boolean'}\n",
        "\n",
        "# @markdown **INTERACTION MODEL** \\\n",
        "# @markdown Enter the **< Interaction Type >** to be viewed. \\\n",
        "# @markdown Select or combine from **`HYDROPHOBIC`**, **`HBOND`**, **`WATERBRIDGE`**,\n",
        "# @markdown **`SALTBRIDGE`**, **`PISTACKING`**, **`PICATION`**, **`HALOGEN`**, **`METAL`**. \\\n",
        "# @markdown *Note: All interactions are selected if not provided.*\n",
        "\n",
        "Interaction_type = \"HBOND, WATERBRIDGE, SALTBRIDGE, PISTACKING, PICATION, HALOGEN, METAL\" # @param {type: 'string'}\n",
        "Show_interaction = True # @param {type: 'boolean'}\n",
        "\n",
        "# @markdown **OTHER OPTIONS** \\\n",
        "# @markdown Miscellaneous visualisation settings.\n",
        "\n",
        "Slab_view = False # @param {type: 'boolean'}\n",
        "\n",
        "dLIG_dFLD = os.path.join(DCK_FLD, View_docked_ligand[:-2])\n",
        "iLIG_iFLD = os.path.join(INT_FLD, View_docked_ligand[:-2])\n",
        "PROT_view_dFile = os.path.join(DCK_FLD, View_protein + '.pdb')\n",
        "NTV_view_dFile = os.path.join(DCK_FLD, View_native_ligand + '.pdb')\n",
        "LIG_view_dFFile = os.path.join(dLIG_dFLD, View_docked_ligand + '.pdb')\n",
        "INT_view_iFFile = os.path.join(iLIG_iFLD, View_docked_ligand + '_interpt.csv')\n",
        "cfg_center, cfg_bxsize = extract_config(cfg_dFile)\n",
        "\n",
        "LBSP = LaboSpace(960, 640)\n",
        "LBSP.load_receptor(PROT_view_dFile)\\\n",
        "    .set_style(\n",
        "        show_represent=Show_protein,\n",
        "        represent_type=Protein_type,\n",
        "        represent_style=builtin_style(\n",
        "            style=Protein_style,\n",
        "            opacity=Protein_opacity))\\\n",
        "    .add_residues(\n",
        "        show_residues=Show_residue,\n",
        "        residue_number=Residue_number)\\\n",
        "    .add_surface(\n",
        "        show_surface=Show_surface,\n",
        "        surface_type=Surface_type,\n",
        "        surface_style=builtin_style(\n",
        "            style=Surface_style,\n",
        "            opacity=Surface_opacity))\n",
        "\n",
        "try:\n",
        "    LBSP.load_ligand(NTV_view_dFile)\\\n",
        "        .set_style(\n",
        "            show_represent=Show_native_ligand,\n",
        "            represent_type=Native_ligand_style,\n",
        "            represent_style={'color': 'grey'})\n",
        "except:\n",
        "    pass\n",
        "\n",
        "LBSP.load_ligand(LIG_view_dFFile)\\\n",
        "    .set_style(\n",
        "        show_represent=Show_docked_ligand,\n",
        "        represent_type=Docked_ligand_style,\n",
        "        represent_style={'colorscheme': 'salmonCarbon'})\n",
        "LBSP.add_interaction(\n",
        "    interaction_file=INT_view_iFFile,\n",
        "    show_interaction=Show_interaction,\n",
        "    select_interaction=Interaction_type)\n",
        "LBSP.add_gridbox(\n",
        "    show_gridbox=Show_gridbox,\n",
        "    center=cfg_center,\n",
        "    bxsize=cfg_bxsize)\n",
        "LBSP.view_space(\n",
        "    slab_view=Slab_view)\n",
        "\n",
        "show_cscale({Show_protein: Protein_style}, {Show_surface: Surface_style})"
      ],
      "metadata": {
        "id": "P9M4swfqIY6j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "---\n",
        " **09 | Save to Google Drive**\n",
        "\n",
        "Finally, we save all the generated data into Google Drive. A copy of the current working directory will be stored in our specified destination in Google Drive."
      ],
      "metadata": {
        "id": "1N4aA3IuIdQJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title **Mount Google Drive**\n",
        "# @markdown This flush and mount Google Drive.\n",
        "\n",
        "drive.flush_and_unmount()\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "id": "93RJq3kVIfHr",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title **Store data**\n",
        "# @markdown Enter the **< Destination >** for storage. \\\n",
        "# @markdown This copies all generated data from current working directory into\n",
        "# @markdown specified destination.\n",
        "\n",
        "Destination = '/content/drive/MyDrive' # @param {type:'string'}\n",
        "\n",
        "DST_FLD = os.path.join(Destination, Job_name)\n",
        "shutil.copytree(WRK_DIR, DST_FLD)\n",
        "\n",
        "print(f'+ {Job_name} stored in {DST_FLD}')"
      ],
      "metadata": {
        "id": "3TZYQbIzIi-5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mL-Qe4loslge"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Phase 5 . Molecular dynamic Simulation.Gromacs**\n",
        "\n",
        "GROMACS is a molecular dynamics package mainly designed for simulations of proteins, lipids, and nucleic acids. It was originally developed in the Biophysical Chemistry department of University of Groningen, and is now maintained by contributors in universities and research centers worldwide.\n",
        "\n",
        "\n",
        "[![DOI](https://img.shields.io/badge/DOI-10.101002/zenodo.8246977-blue)](https://pubmed.ncbi.nlm.nih.gov/16211538/)\n",
        "\n"
      ],
      "metadata": {
        "id": "NPHwCHBHswR-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "#Let us check the Google COlab resources - 1GPU and 2 CPU with 1TB HDD and 12GB RAM\n",
        "%%shell\n",
        "lscpu\n",
        "nvidia-smi"
      ],
      "metadata": {
        "id": "pY_TjEzGs52b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "wget https://github.com/Kitware/CMake/releases/download/v3.20.0-rc1/cmake-3.20.0-rc1.tar.gz\n",
        "tar xfz cmake-3.20.0-rc1.tar.gz"
      ],
      "metadata": {
        "id": "Y1MyMKLcuVwI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "mkdir /content/cmake-3.20.0-rc1/build\n",
        "cd /content/cmake-3.20.0-rc1/build\n",
        "cmake /content/cmake-3.20.0-rc1/\n",
        "make -j 2\n",
        "make install"
      ],
      "metadata": {
        "id": "w6qB8bvbULz7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "wget ftp://ftp.gromacs.org/gromacs/gromacs-2024.tar.gz\n",
        "tar -xzvf gromacs-2024.tar.gz\n",
        "cd /content/gromacs-2024\n",
        "mkdir /content/gromacs-2024/build\n",
        "cd /content/gromacs-2024/build\n",
        "cmake .. -DGMX_BUILD_OWN_FFTW=ON -DREGRESSIONTEST_DOWNLOAD=ON -DGMX_GPU=CUDA\n",
        "make -j 2\n",
        "make install\n",
        "source /usr/local/gromacs/bin/GMX"
      ],
      "metadata": {
        "id": "YT7Nf1QoURZ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "source /usr/local/gromacs/bin/GMXRC\n",
        "cd /content/drive/MyDrive/X1B341MD/content/14\n",
        "ls\n",
        "\n",
        "##gmx pdb2gmx -f \"afx1b341v2.pdb\" -o \"afx1b341v2.gro\" -p \"afx1b341v2.top\" -ff charmm27 -water tip3p -ignh -missing\n",
        "##gmx editconf -f \"afx1b341v2.gro\" -c -d 1 -bt cubic -o\n",
        "##gmx solvate -cp out.gro -cs -p \"afx1b341v2.top\" -o \"afx1b341v2_box\"\n",
        "##gmx grompp -f ions.mdp -c \"afx1b341v2_box.gro\" -p \"afx1b341v2.top\" -o \"afx1b341v2_charged\" -maxwarn 2\n",
        "##echo 'SOL' | gmx genion -s \"afx1b341v2_charged.tpr\" -o \"afx1b341v2_charged\" -p \"afx1b341v2.top\" -neutral\n",
        "##grace -nxy \"afx1b341v2_potentialsd.xvg\" -hdevice PNG -hardcopy -printfile \"../content/drive/X1B341/MyDrive/X1B341MD/content/14/fig/afx1b341v2_potentialsd.png\"\n",
        "\n",
        "##gmx grompp -f PME_em.mdp -c \"afx1b341v2_charged.gro\" -p \"afx1b341v2.top\" -o \"afx1b341v2_charged\" -maxwarn 2\n",
        "##gmx mdrun -v -s \"afx1b341v2_charged.tpr\" -deffnm \"afx1b341v2_sd_em\"\n",
        "##echo '10 0' | gmx energy -f \"afx1b341v2_sd_em.edr\" -o \"afx1b341v2_potentialsd.xvg\"\n",
        "##grace -nxy \"afx1b341v2_potentialsd.xvg\" -hdevice PNG -hardcopy -printfile\n",
        "##apt-get install grace\n",
        "\n",
        "##gmx grompp -f PME_emcg.mdp -c \"afx1b341v2_sd_em.gro\" -p \"afx1b341v2.top\" -o \"afx1b341v2_cg_em\" -maxwarn 2\n",
        "##gmx mdrun -v -s \"afx1b341v2_cg_em.tpr\" -deffnm \"afx1b341v2_cg_em\"\n",
        "##echo '10 0' | gmx energy -f \"afx1b341v2_cg_em.edr\" -o \"afx1b341v2_potentialcg.xvg\"\n",
        "##grace -nxy \"afx1b341v2_potentialcg.xvg\" -hdevice PNG -hardcopy -printfile \"/content/content/fig/afx1b341v2_potentialcg.png\"\n",
        "##gmx grompp -f nvt4.2.mdp -c \"afx1b341v2_cg_em.gro\" -r \"afx1b341v2_cg_em.gro\" -p \"afx1b341v2.top\" -o \"afx1b341v2_nvt.tpr\" -maxwarn 2\n",
        "##gmx mdrun -v -s \"afx1b341v2_nvt.tpr\" -deffnm \"afx1b341v2_nvt\"\n",
        "##echo '16 0' | gmx energy -f \"afx1b341v2_nvt.edr\" -o \"afx1b341v2_temperature_nvt.xvg\"\n",
        "##grace -nxy \"afx1b341v2_temperature_nvt.xvg\" -hdevice PNG -hardcopy -printfile \"/content/content/fig/afx1b341v2_temperature_nvt.png\"\n",
        "##gmx grompp -f npt4.1.mdp -c \"afx1b341v2_nvt.gro\" -r \"afx1b341v2_nvt.gro\" -p \"afx1b341v2.top\" -o \"afx1b341v2_npt.tpr\" -maxwarn 2\n",
        "##gmx mdrun  -v -s \"afx1b341v2_npt.tpr\" -deffnm \"afx1b341v2_npt\"\n",
        "##echo '16 0' | gmx energy -f \"afx1b341v2_npt.edr\" -o \"afx1b341v2_temperature_npt.xvg\"\n",
        "#çgmx grompp -f md5.mdp -c \"afx1b341v2_npt.gro\" -p \"afx1b341v2.top\" -o \"afx1b341v2_pr\" -maxwarn 2\n",
        "gmx mdrun  -v -s \"afx1b341v2_pr.tpr\" -deffnm \"afx1b341v2_pr\"\n",
        "\n",
        "##gmx grompp -f md5.mdp -p afx1b341v2.top -c afx1b341v2_npt.gro -t afx1b341v2_pr.cpt -o new.tpr\n",
        "##gmx mdrun   -deffnm afx1b341v2_pr2  -cpi afx1b341v2_pr.cpt -s new.tpr -append\n",
        "##gmx mdrun -v -s new.tpr -cpi afx1b341v2_pr.cpt -deffnm afx1b341v2_pr\n"
      ],
      "metadata": {
        "id": "TF-S_PZEUWBa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tnvD6dMaXSMZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Phase 6. Rapid protein stability prediction using deep learning representations**\n",
        "\n",
        "Preprint pipeline version for predicting protein variants **thermodynamic stability changes** ($\\Delta \\Delta G$) using a deep learning representation. The program, using as input a protein structure (uploaded as PDB) returns stability predictions ($\\Delta \\Delta G$ in kcal/mol) for each variant at each position of the query protein.\n",
        "\n",
        "\n",
        "[![DOI](https://img.shields.io/badge/DOI-10.1101/zenodo.8246977-blue)](https://www.biorxiv.org/content/10.1101/2022.07.14.500157v1)\n"
      ],
      "metadata": {
        "id": "H5DscUjFc4s9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  <b><font color='#009e74'> Reminders and Important informations:</font></b>\n",
        "- This notebook  <b><font color='#d55c00'>must</font></b> be run in a Colab GPU session (go to page menu: `Runtime`->  `Change runtime type` -> select `GPU` and confirm\n",
        "- Run <b><font color='#d55c00'>ONE</font></b> cell at a time, <b><font color='#d55c00'>DON'T USE</font></b> the `Runtime`->  `Run all` function as condacolab installation requires a restart of the kernel.\n",
        "- Cells labelled <b><font color='#56b4e9'>PRELIMINARY OPERATIONS </font></b>  must be run <b><font color='#d55c00'>ONE</font></b> at a time and <b><font color='#d55c00'>ONCE</font></b> at the start and skipped for new predictions.\n",
        "- Cells named as  <b><font color='#56b4e9'>PRELIMINARY OPERATIONS </font></b> have to be run <b><font color='#d55c00'>ONE BY ONE</font></b>  and <font color='#d55c00'>ONCE only at the start</font></b>  and  skipped for new predictions.\n",
        "- <b><font color='#d55c00'>ONE</font></b> single pdb at the time can be processed by the pipeline.\n",
        "- A  <b><font color='#d55c00'>new run</font></b> can be perform input direcly the new structure in the pdb upload cell and run the prediction cell again\n",
        "\n",
        "****"
      ],
      "metadata": {
        "id": "xZ3iM84ZdZMt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <b><font color='#009e74'>PIPELINE : PRELIMINARY OPERATIONS </font></b>\n",
        "These cells MUST be run <b><font color='#d55c00'>INDIVIDUALLY AND SEQUENTIALLY</font></b>, and only once at the start of the notebook.\n",
        "****"
      ],
      "metadata": {
        "id": "l5GuVHBKdjwu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title <b><font color='#56b4e9'>PRELIMINARY OPERATIONS</font>: Install condacolab\n",
        "#@markdown Run this cell to install condacolab. After running this cell the kernel will be automatically restarted (wait ~1min before run the next cell)\n",
        "\n",
        "#@markdown **N.B: This cell should be run only ONCE at the START of the notebook.**\n",
        "try:\n",
        "    import google.colab\n",
        "    !pip install condacolab\n",
        "    import condacolab\n",
        "    condacolab.install()\n",
        "except ModuleNotFoundError:\n",
        "    pass"
      ],
      "metadata": {
        "id": "in-pqQR-doAt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title <b><font color='#56b4e9'>PRELIMINARY OPERATIONS</font>: Setup enviroment and dependencies</b>\n",
        "\n",
        "#@markdown Run this cell to install the required enviroment and dependencies (~10 minutes)\n",
        "\n",
        "#@markdown **N.B: This cell should be run only ONCE at the START of the notebook.**\n",
        "! rm -r sample_data\n",
        "\n",
        "# install dependencies present in pip\n",
        "! pip install numpy==1.17.3 torch==1.7.1 biopython==1.72 matplotlib pdb-tools &> /dev/null\n",
        "! pip install --upgrade pdb-tools\n",
        "! echo \"-> packages with pip installed!\"\n",
        "\n",
        "! mamba install  mpl-scatter-density ptitprince pdbfixer openmm=7.5.1 pandas=1.4.4 -c omnia -c conda-forge -c anaconda -c defaults --yes &> /dev/null\n",
        "! echo \"-> packages with conda installed!\"\n",
        "\n"
      ],
      "metadata": {
        "id": "3kpwZfc3dtz0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title <b><font color='#56b4e9'>PRELIMINARY OPERATIONS</font>: Retrieve parameters and RaSP files</b>\n",
        "\n",
        "#@markdown Run this cell to import RaSP files and parameters\n",
        "\n",
        "#@markdown **N.B: This cell should be run only ONCE at the START of the notebook.**\n",
        "%%bash\n",
        "\n",
        "#install svn\n",
        "apt-get install -qq subversion &> /dev/null\n",
        "\n",
        "#mkdir of necessary folders\n",
        "mkdir data\n",
        "mkdir data/test\n",
        "mkdir data/test/predictions\n",
        "mkdir data/test/predictions/raw\n",
        "mkdir data/test/predictions/cleaned\n",
        "mkdir data/test/predictions/parsed\n",
        "mkdir output/\n",
        "mkdir output/predictions\n",
        "\n",
        "#download project folders from github\n",
        "\n",
        "svn checkout https://github.com/KULL-Centre/papers/trunk/2022/ML-ddG-Blaabjerg-et-al/src  &> /dev/null\n",
        "svn checkout https://github.com/KULL-Centre/papers/trunk/2022/ML-ddG-Blaabjerg-et-al/output/cavity_models  &> /dev/null\n",
        "svn checkout https://github.com/KULL-Centre/papers/trunk/2022/ML-ddG-Blaabjerg-et-al/output/ds_models  &> /dev/null\n",
        "\n",
        "wget -cq https://github.com/KULL-Centre/papers/raw/papers/2022/ML-ddG-Blaabjerg-et-al/data/pdb_frequencies.npz -o /content/data/pdb_frequencies.npz\n",
        "wget -cq https://github.com/KULL-Centre/papers/raw/main/2022/ML-ddG-Blaabjerg-et-al/colab_additonals/colab_additional.zip\n",
        "\n",
        "#extra files for runnin the notebooks\n",
        "\n",
        "mv ds_models ./output/\n",
        "mv cavity_models ./output/\n",
        "\n",
        "unzip colab_additional.zip &> /dev/null\n",
        "rm colab_additional.zip\n",
        "\n",
        "mv /content/colab_additional/best_model_path.txt /content/output/cavity_models/\n",
        "mv /content/colab_additional/clean_pdb.py /content/src/pdb_parser_scripts/\n",
        "mv /content/colab_additional/helpers.py /content/src/\n",
        "mv /content/colab_additional/pdb_frequencies.npz /content/data/\n",
        "\n",
        "echo \"---> Github data imported!\"\n",
        "\n",
        "#get and compile reduce\n",
        "\n",
        "cd src/pdb_parser_scripts\n",
        "git clone https://github.com/rlabduke/reduce.git\n",
        "cd reduce/\n",
        "make &> /dev/null\n",
        "\n",
        "mv /content/colab_additional/reduce /content/src/pdb_parser_scripts/reduce/\n",
        "\n",
        "chmod +x /content/src/pdb_parser_scripts/reduce/reduce\n",
        "echo \"----> reduce installed\"\n",
        "\n",
        "rm -r /content/colab_additional\n",
        "#@markdown ****"
      ],
      "metadata": {
        "cellView": "form",
        "id": "FZhyi2tpd5Qx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title <b><font color='#56b4e9'>PRELIMINARY OPERATIONS</font>: Import python libraries, functions and setup common variables</b>\n",
        "\n",
        "#@markdown Run this cell to import libraries and functions necessary for the pipeline.\n",
        "\n",
        "#@markdown **N.B: This cell should be run only ONCE at the START of the notebook.**\n",
        "\n",
        "import sys\n",
        "sys.path.append(\"/usr/local/lib/python3.7/site-packages\")\n",
        "\n",
        "import glob\n",
        "import os\n",
        "import random\n",
        "import pathlib\n",
        "import subprocess\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import time\n",
        "import datetime\n",
        "import matplotlib\n",
        "from pdbfixer import PDBFixer\n",
        "from simtk.openmm.app import PDBFile\n",
        "from Bio.PDB.Polypeptide import index_to_one, one_to_index\n",
        "from collections import OrderedDict\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from google.colab import files\n",
        "\n",
        "sys.path.append('./src/')\n",
        "\n",
        "from cavity_model import (\n",
        "     CavityModel,\n",
        "     DownstreamModel,\n",
        "     ResidueEnvironment,\n",
        "     ResidueEnvironmentsDataset,\n",
        ")\n",
        "\n",
        "from helpers import (\n",
        "     populate_dfs_with_resenvs,\n",
        "     remove_disulfides,\n",
        "     fermi_transform,\n",
        "     inverse_fermi_transform,\n",
        "     init_lin_weights,\n",
        "     ds_pred,\n",
        "     cavity_to_prism,\n",
        "     get_seq_from_variant,\n",
        ")\n",
        "\n",
        "from visualization import (\n",
        "     hist_plot,\n",
        ")\n",
        "\n",
        "#Extra function to fix pdb\n",
        "\n",
        "# Setup pipeline parameters\n",
        "## Set seeds\n",
        "np.random.seed(0)\n",
        "random.seed(0)\n",
        "torch.manual_seed(0)\n",
        "torch.cuda.manual_seed(0)\n",
        "torch.cuda.manual_seed_all(0)\n",
        "torch.backends.cudnn.enabled = False\n",
        "torch.backends.cudnn.benchmark = False\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "## Main deep parameters\n",
        "DEVICE = \"cuda\"  # \"cpu\" or \"cuda\"\n",
        "NUM_ENSEMBLE = 10\n",
        "TASK_ID = int(1)\n",
        "PER_TASK = int(1)\n",
        "\n",
        "#@markdown ****"
      ],
      "metadata": {
        "cellView": "form",
        "id": "hY8Me-4xeAiR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title <b><font color='#56b4e9'> PDB upload</font></b>\n",
        "\n",
        "#@markdown Choose between <b><font color='#d55c00'> ONE</font></b> of the possible input sources for the target pdb and <b><font color='#d55c00'>leave the other cells empty or unmarked</font></b>\n",
        "#@markdown - AlphaFold2 PDB (v4) via Uniprot ID:\n",
        "AF_ID ='P68871'#@param {type:\"string\"}\n",
        "#@markdown - PDB ID (imported from RCSB PDB):\n",
        "PDB_ID =''#@param {type:\"string\"}\n",
        "#@markdown - Upload custom PDB\n",
        "PDB_custom =False#@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown\n",
        "\n",
        "#@markdown Select target chain (default A)\n",
        "chain='A' #@param {type:'string'}\n",
        "\n",
        "if os.path.exists(\"/content/query_protein.pdb\"):\n",
        "    os.remove(\"/content/query_protein.pdb\")\n",
        "if os.path.exists(\"/content/data/test/predictions/raw/query_protein_uniquechain.pdb\"):\n",
        "    os.remove(\"/content/data/test/predictions/raw/query_protein_uniquechain.pdb\")\n",
        "if os.path.exists(\"/content/data/test/predictions/cleaned/query_protein_uniquechain_clean.pdb\"):\n",
        "    os.remove(\"/content/data/test/predictions/cleaned/query_protein_uniquechain_clean.pdb\")\n",
        "if os.path.exists(\"/content/data/test/predictions/parsed/query_protein_uniquechain_clean_coordinate_features.npz\"):\n",
        "    os.remove(\"/content/data/test/predictions/parsed/query_protein_uniquechain_clean_coordinate_features.npz\")\n",
        "\n",
        "if PDB_custom:\n",
        "  print('Upload PDB file:')\n",
        "  uploaded_pdb = files.upload()\n",
        "  for fn in uploaded_pdb.keys():\n",
        "    os.rename(fn, f\"/content/query_protein.pdb\")\n",
        "    print('PDB file correctly loaded')\n",
        "elif (AF_ID !='') and (len(AF_ID)>=6) :\n",
        "    subprocess.call(['curl','-s','-f',f'https://alphafold.ebi.ac.uk/files/AF-{AF_ID}-F1-model_v4.pdb','-o','/content/query_protein.pdb'])\n",
        "elif (PDB_ID !='') and (len(PDB_ID)==4):\n",
        "    subprocess.call(['curl','-s','-f',f'https://files.rcsb.org/download/{PDB_ID}.pdb','-o','/content/query_protein.pdb'])\n",
        "\n",
        "else:\n",
        "  print(f'ERROR: any PDB uploaded, please select one of the above inputs')\n",
        "\n",
        "#@markdown N.B. This cell will also perform preliminary operations to correcly format the uploaded PDB\n",
        "\n",
        "## remove other chains and move to raw folder\n",
        "!pdb_selchain -\"$chain\" /content/query_protein.pdb | pdb_delhetatm | pdb_delres --999:0:1 | pdb_fixinsert | pdb_tidy  > /content/data/test/predictions/raw/query_protein_uniquechain.pdb\n",
        "# Select PDBs to run during this task - could be simplified if we decide to set PER_TASK = 1 for all cases\n",
        "\n",
        "pdb_input_dir = \"data/test/predictions/raw/\"\n",
        "input_pdbs = sorted(list(filter(lambda x: x.endswith(\".pdb\"), os.listdir('data/test/predictions/raw/'))))\n",
        "start = (TASK_ID-1)*(PER_TASK)\n",
        "end = (TASK_ID*PER_TASK)\n",
        "if end > len(input_pdbs):\n",
        "    end = len(input_pdbs) #avoid end index exceeding length of list\n",
        "pdbs = input_pdbs[start:end]\n",
        "pdb_names = [i.split(\".\")[0] for i in pdbs]\n",
        "print(pdb_names)\n",
        "print(f\"Pre-processing PDBs ...\")\n",
        "\n",
        "!python3 /content/src/pdb_parser_scripts/clean_pdb.py --pdb_file_in /content/data/test/predictions/raw/query_protein_uniquechain.pdb --out_dir /content/data/test/predictions/cleaned/ --reduce_exe /content/src/pdb_parser_scripts/reduce/reduce #&> /dev/null\n",
        "!python3 /content/src/pdb_parser_scripts/extract_environments.py --pdb_in /content/data/test/predictions/cleaned/query_protein_uniquechain_clean.pdb  --out_dir /content/data/test/predictions/parsed/  #&> /dev/null\n",
        "\n",
        "if os.path.exists(\"/content/data/test/predictions/parsed/query_protein_uniquechain_clean_coordinate_features.npz\"):\n",
        "  print(f\"Pre-processing PDBs correctly ended\")\n",
        "else:\n",
        "  print(f\"Pre-processing PDB didn't end correcly, please check input informations\")\n",
        "\n",
        "#@markdown ****"
      ],
      "metadata": {
        "cellView": "form",
        "id": "L_Y0YLOqeFsK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#@title <b><font color='#56b4e9'> Pipeline RUN </font></b>\n",
        "\n",
        "#@markdown <b><font color='#d55c00'>Execute the cell</font></b> to run the pipeline and generate **saturation mutagenesis predictions of thermodynamic stability changes** predictions\n",
        "\n",
        "### Pre-process structure data\n",
        "\n",
        "# Create temporary residue environment datasets to more easily match ddG data\n",
        "pdb_filenames_ds = sorted(glob.glob(f\"/content/data/test/predictions/parsed/*coord*\"))\n",
        "\n",
        "dataset_structure = ResidueEnvironmentsDataset(pdb_filenames_ds, transformer=None)\n",
        "\n",
        "resenv_dataset = {}\n",
        "for resenv in dataset_structure:\n",
        "    if AF_ID!='':\n",
        "      key = (f\"--{AF_ID}--{resenv.chain_id}--{resenv.pdb_residue_number}--{index_to_one(resenv.restype_index)}--\"\n",
        "          )\n",
        "    elif PDB_ID!='':\n",
        "      key = (f\"--{PDB_ID}--{resenv.chain_id}--{resenv.pdb_residue_number}--{index_to_one(resenv.restype_index)}--\"\n",
        "          )\n",
        "    else:\n",
        "      key = (f\"--{'CUSTOM'}--{resenv.chain_id}--{resenv.pdb_residue_number}--{index_to_one(resenv.restype_index)}--\"\n",
        "          )\n",
        "    resenv_dataset[key] = resenv\n",
        "df_structure_no_mt = pd.DataFrame.from_dict(resenv_dataset, orient='index', columns=[\"resenv\"])\n",
        "df_structure_no_mt.reset_index(inplace=True)\n",
        "df_structure_no_mt[\"index\"]=df_structure_no_mt[\"index\"].astype(str)\n",
        "res_info = pd.DataFrame(df_structure_no_mt[\"index\"].str.split('--').tolist(),\n",
        "                        columns = ['blank','pdb_id','chain_id','pos','wt_AA', 'blank2'])\n",
        "\n",
        "df_structure_no_mt[\"pdbid\"] = res_info['pdb_id']\n",
        "df_structure_no_mt[\"chainid\"] = res_info['chain_id']\n",
        "df_structure_no_mt[\"variant\"] = res_info[\"wt_AA\"] + res_info['pos'] + \"X\"\n",
        "aa_list = [\"A\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\", \"I\", \"K\", \"L\",\n",
        "            \"M\", \"N\", \"P\", \"Q\", \"R\", \"S\", \"T\", \"V\", \"W\", \"Y\"]\n",
        "df_structure = pd.DataFrame(df_structure_no_mt.values.repeat(20, axis=0), columns=df_structure_no_mt.columns)\n",
        "for i in range(0, len(df_structure), 20):\n",
        "    for j in range(20):\n",
        "        df_structure.iloc[i+j, :][\"variant\"] = df_structure.iloc[i+j, :][\"variant\"][:-1] + aa_list[j]\n",
        "df_structure.drop(columns=\"index\", inplace=True)\n",
        "\n",
        "# Load PDB amino acid frequencies used to approximate unfolded states\n",
        "pdb_nlfs = -np.log(np.load(f\"{os.getcwd()}/data/pdb_frequencies.npz\")[\"frequencies\"])\n",
        "\n",
        "# # Add wt and mt idxs and freqs to df\n",
        "\n",
        "df_structure[\"wt_idx\"] = df_structure.apply(lambda row: one_to_index(row[\"variant\"][0]), axis=1)\n",
        "df_structure[\"mt_idx\"] = df_structure.apply(lambda row: one_to_index(row[\"variant\"][-1]), axis=1)\n",
        "df_structure[\"wt_nlf\"] = df_structure.apply(lambda row: pdb_nlfs[row[\"wt_idx\"]], axis=1)\n",
        "df_structure[\"mt_nlf\"] = df_structure.apply(lambda row: pdb_nlfs[row[\"mt_idx\"]], axis=1)\n",
        "\n",
        "# Define models\n",
        "best_cavity_model_path = open(f\"/content/output/cavity_models/best_model_path.txt\", \"r\").read()\n",
        "cavity_model_net = CavityModel(get_latent=True).to(DEVICE)\n",
        "cavity_model_net.load_state_dict(torch.load(f\"{best_cavity_model_path}\"))\n",
        "cavity_model_net.eval()\n",
        "ds_model_net = DownstreamModel().to(DEVICE)\n",
        "ds_model_net.apply(init_lin_weights)\n",
        "ds_model_net.eval()\n",
        "\n",
        "###set start time\n",
        "start_time = time.perf_counter()\n",
        "\n",
        "# Make ML predictions\n",
        "print(f\"Starting downstream model prediction\")\n",
        "dataset_key=\"predictions\"\n",
        "df_ml = ds_pred(cavity_model_net,\n",
        "                ds_model_net,\n",
        "                df_structure,\n",
        "                dataset_key,\n",
        "                NUM_ENSEMBLE,\n",
        "                DEVICE,\n",
        "                )\n",
        "print(f\"Finished downstream model prediction\")\n",
        "end_time = time.perf_counter()\n",
        "elapsed = datetime.timedelta(seconds = end_time - start_time)\n",
        "print(\"Complete - prediction execution took\", elapsed)\n",
        "\n",
        "elapsed = datetime.timedelta(seconds = end_time - start_time)\n",
        "print(\"Generating output files\")\n",
        "#Merge and save data with predictions\n",
        "\n",
        "df_total = df_structure.merge(df_ml, on=['pdbid','chainid','variant'], how='outer')\n",
        "#df_total[\"b_factors\"] = df_total.apply(lambda row: row[\"resenv\"].b_factors, axis=1)\n",
        "df_total = df_total.drop(\"resenv\", 1)\n",
        "print(f\"{len(df_structure)-len(df_ml)} data points dropped when matching total data with ml predictions in: {dataset_key}.\")\n",
        "\n",
        "# Parse output into separate files by pdb, print to PRISM format\n",
        "for pdbid in df_total[\"pdbid\"].unique():\n",
        "    df_pdb = df_total[df_total[\"pdbid\"]==pdbid]\n",
        "    for chainid in df_pdb[\"chainid\"].unique():\n",
        "        pred_outfile = f\"{os.getcwd()}/output/{dataset_key}/cavity_pred_{pdbid}_{chainid}.csv\"\n",
        "        print(f\"Parsing predictions from pdb: {pdbid}{chainid} into {pred_outfile}\")\n",
        "        df_chain = df_pdb[df_pdb[\"chainid\"]==chainid]\n",
        "        df_chain = df_chain.assign(pos = df_chain[\"variant\"].str[1:-1])\n",
        "        df_chain['pos'] = pd.to_numeric(df_chain['pos'])\n",
        "        first_res_no = min(df_chain[\"pos\"])\n",
        "        df_chain = df_chain.assign(wt_AA = df_chain[\"variant\"].str[0])\n",
        "        df_chain = df_chain.assign(mt_AA = df_chain[\"variant\"].str[-1])\n",
        "        seq = get_seq_from_variant(df_chain)\n",
        "        df_chain.to_csv(pred_outfile, index=False)\n",
        "        prism_outfile = f\"/content/output/{dataset_key}/prism_cavity_{pdbid}_{chainid}.txt\"\n",
        "\n",
        "        # if (AF_ID !=''):\n",
        "        #   prism_outfile = f\"/content/output/{dataset_key}/prism_cavity_{AF_ID}_{chainid}.txt\"\n",
        "        # elif (PDB_ID !=''):\n",
        "        #   prism_outfile = f\"/content/output/{dataset_key}/prism_cavity_{PDB_ID}_{chainid}.txt\"\n",
        "        # elif PDB_custom:\n",
        "        #   prism_outfile = f\"/content/output/{dataset_key}/prism_cavity_XXXX_{chainid}.txt\"\n",
        "        cavity_to_prism(df_chain, pdbid, chainid, seq, prism_outfile)\n",
        "\n",
        "# End timer and print result\n",
        "#!rm /content/output/predictions/*xxxx*.csv\n",
        "elapsed = datetime.timedelta(seconds = end_time - start_time)\n",
        "print(\"Complete - files generated\")\n",
        "\n",
        "#@markdown ****"
      ],
      "metadata": {
        "cellView": "form",
        "id": "bGhgesc0eL8r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title <b><font color='#56b4e9'> Download results as archive </font></b>\n",
        "\n",
        "#@markdown Run the cell to <b><font color='#009e74'> download a .zip archive </font></b> with prediction files for the <ins>current run</ins>.\n",
        "\n",
        "#@markdown <ins>Tick</ins> the next box if you ran multiple predictions and you want to <ins>download all of them</ins>.\n",
        "\n",
        "download_all_predictions= False #@param {type:\"boolean\"}\n",
        "\n",
        "if download_all_predictions:\n",
        "  os.system( \"zip -r {} {}\".format( f\"predictions_output_all.zip\" , f\"/content/output/predictions/*\" ) )\n",
        "  files.download(f\"predictions_output_all.zip\")\n",
        "else:\n",
        "  if (AF_ID !=''):\n",
        "    os.system( \"zip -r {} {}\".format( f\"predictions_output_{AF_ID}.zip\" , f\"/content/output/predictions/*{AF_ID}*\" ) )\n",
        "    files.download(f\"predictions_output_{AF_ID}.zip\")\n",
        "  elif (PDB_ID !=''):\n",
        "    os.system( \"zip -r {} {}\".format( f\"predictions_output_{PDB_ID}.zip\" , f\"/content/output/predictions/*{PDB_ID}*\" ) )\n",
        "    files.download(f\"predictions_output_{PDB_ID}.zip\")\n",
        "  else:\n",
        "    os.system( \"zip -r {} {}\".format( f\"predictions_output.zip\" , f\"/content/output/predictions\" ) )\n",
        "    files.download(f\"predictions_output.zip\")\n",
        "\n",
        "  if download_all_predictions:\n",
        "    os.system( \"zip -r {} {}\".format( f\"predictions_output.zip\" , f\"/content/output/predictions\" ) )\n",
        "    files.download(f\"predictions_output_all.zip\")\n",
        "\n",
        "#@markdown **P.S.: prediction files are also stored in the colab file system folder: `/output/predictions/`**\n",
        "#@markdown ****"
      ],
      "metadata": {
        "cellView": "form",
        "id": "O1U8umSueRxp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CHANGING LOG**\n",
        "\n",
        "- 12th April 2023: AlphaFold2 database version update to v4.\n",
        "- 3rd April 2023: Torch version and packagess updated for python 3.9\n",
        "\n",
        "\n",
        "\n",
        "**Troubleshooting**\n",
        "\n",
        "- Check that the runtime type is set to GPU at \"Runtime\" -> \"Change runtime type\".\n",
        "- Try to restart the session \"Runtime\" -> \"Factory reset runtime\".\n",
        "- Run the PRELIMINARY OPERATION one at the time, to avoid crashes.\n",
        "- Check your input pdb.\n",
        "\n",
        "\\\\\n",
        "\n",
        "**Known problems:**\n",
        "\n",
        "- Condacolab need to restart the notebook kernel, so preliminart cells MUST be run one at the time to allow this.\n",
        "- Residues with numeration index below 0 are not supported by the output file parser and thus they deleted from the pdb in the pre-processing step.\n",
        "- Insertion annotations in the pdb are not supported. Any annotations is actually deleted during the pre-processing step.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "e8HypMcoeV6U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Phase 8 . Carcinogenicity Prediction**\n",
        "\n",
        "\n",
        "Metabokiller offers a novel, machine learning-based approach that accurately recognizes carcinogens by quantitatively assessing their chemical composition as well as potential to induce proliferation, oxidative stress, genomic instability, alterations in epigenetic signatures, and activation of anti-apoptotic pathways, and therefore, obviates the absolute need for bonafide (non)carcinogens for training model. Concomitant with the carcinogenicity prediction, it also reveals the contribution of the aforementioned biochemical processes in carcinogenicity, thereby making the proposed approach highly interpretable.\n",
        "\n",
        "\n",
        "\n",
        "[![DOI](https://img.shields.io/badge/DOI-10.10138/zenodo.8246977-blue)](https://www.nature.com/articles/d44151-022-00084-8/)\n",
        "\n"
      ],
      "metadata": {
        "id": "Tsq5FnuKSadQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "pip install signaturizer\n",
        "pip install lime\n",
        "pip install kora -q\n",
        "pip install Metabokiller==0.1"
      ],
      "metadata": {
        "id": "vSEqH6heTptO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import kora.install.rdkit\n",
        "from Metabokiller import mk_predictor as mk\n",
        "from Metabokiller import EnsembleMK"
      ],
      "metadata": {
        "id": "u8h7oPz5TsEi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "smiles = ['OC(=O)CCC(C(=O)O)O']\n",
        "result = mk.Epigenetics(smiles)\n",
        "#Output predction dataframe\n",
        "result"
      ],
      "metadata": {
        "id": "1zaIhC1YT8_X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Meatbokiller Ensemble with Molecular Explanation**"
      ],
      "metadata": {
        "id": "yVKgST1lUrnf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Additional packages for Explanation Graphs\n",
        "from matplotlib.backends.backend_pdf import PdfPages\n",
        "from matplotlib import pyplot as plt"
      ],
      "metadata": {
        "id": "72NyNAQMUXbw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "smiles = ['OC(=O)CCC(C(=O)O)O']"
      ],
      "metadata": {
        "id": "acQhGiaPU1yA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result,explanation = EnsembleMK.predict(['CC(C)[N+](=O)[O-]'],explainability=True)"
      ],
      "metadata": {
        "id": "VU5iCaWjU4yN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Output predction dataframe\n",
        "result"
      ],
      "metadata": {
        "id": "zE80XOITVAYJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Saving the Molecular Explanation graphs into pdfs\n",
        "pdf = PdfPages(\"Ensmble-Result.pdf\")\n",
        "for fig in explanation:\n",
        "  fig.savefig(pdf, format='pdf')\n",
        "pdf.close()"
      ],
      "metadata": {
        "id": "BbECjC9lVD7i"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}